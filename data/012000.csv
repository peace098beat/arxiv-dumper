id,guidislink,link,updated,updated_parsed,published,published_parsed,title,title_detail,summary,summary_detail,authors,author_detail,author,links,arxiv_primary_category,tags,arxiv_comment,arxiv_journal_ref,arxiv_affiliation
http://arxiv.org/abs/2106.12047v1,True,http://arxiv.org/abs/2106.12047v1,2021-06-15T14:06:54Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=15, tm_hour=14, tm_min=6, tm_sec=54, tm_wday=1, tm_yday=166, tm_isdst=0)",2021-06-15T14:06:54Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=15, tm_hour=14, tm_min=6, tm_sec=54, tm_wday=1, tm_yday=166, tm_isdst=0)","Fluctuations of water quality time series in rivers follow
  superstatistics","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Fluctuations of water quality time series in rivers follow\n  superstatistics'}","Superstatistics is a general method from nonequilibrium statistical physics
which has been applied to a variety of complex systems, ranging from
hydrodynamic turbulence to traffic delays and air pollution dynamics. Here, we
investigate water quality time series (such as dissolved oxygen concentrations
and electrical conductivity) as measured in rivers, and provide evidence that
they exhibit superstatistical behaviour. Our main example are time series as
recorded in the river Chess in South East England. Specifically, we use
seasonal detrending and empirical mode decomposition (EMD) to separate trends
from fluctuations for the measured data. With either detrending method, we
observe heavy-tailed fluctuation distributions, which are well described by a
log-normal superstatistics for dissolved oxygen. Contrarily, we find a double
peaked non-standard superstatistics for the electrical conductivity data, which
we model using two combined $\chi^2$-distributions.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Superstatistics is a general method from nonequilibrium statistical physics\nwhich has been applied to a variety of complex systems, ranging from\nhydrodynamic turbulence to traffic delays and air pollution dynamics. Here, we\ninvestigate water quality time series (such as dissolved oxygen concentrations\nand electrical conductivity) as measured in rivers, and provide evidence that\nthey exhibit superstatistical behaviour. Our main example are time series as\nrecorded in the river Chess in South East England. Specifically, we use\nseasonal detrending and empirical mode decomposition (EMD) to separate trends\nfrom fluctuations for the measured data. With either detrending method, we\nobserve heavy-tailed fluctuation distributions, which are well described by a\nlog-normal superstatistics for dissolved oxygen. Contrarily, we find a double\npeaked non-standard superstatistics for the electrical conductivity data, which\nwe model using two combined $\\chi^2$-distributions.'}","[{'name': 'Benjamin Sch√§fer'}, {'name': 'Catherine M. Heppell'}, {'name': 'Hefin Rhys'}, {'name': 'Christian Beck'}]",{'name': 'Christian Beck'},Christian Beck,"[{'href': 'http://arxiv.org/abs/2106.12047v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.12047v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'physics.ao-ph', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'physics.ao-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.bio-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.data-an', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.AP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",,,
http://arxiv.org/abs/2106.08328v1,True,http://arxiv.org/abs/2106.08328v1,2021-06-15T18:00:00Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=15, tm_hour=18, tm_min=0, tm_sec=0, tm_wday=1, tm_yday=166, tm_isdst=0)",2021-06-15T18:00:00Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=15, tm_hour=18, tm_min=0, tm_sec=0, tm_wday=1, tm_yday=166, tm_isdst=0)","Eclipsing Binaries Found by the EREBOS Project: Gaia DR2
  6097540197980557440 -- A Deeply Eclipsing sdB+dM System","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Eclipsing Binaries Found by the EREBOS Project: Gaia DR2\n  6097540197980557440 -- A Deeply Eclipsing sdB+dM System'}","We present time-series spectroscopy and photometry of Gaia DR2
6097540197980557440, a new deeply-eclipsing hot subdwarf B (sdB) + M dwarf (dM)
binary. We discovered this object during the course of the Eclipsing Reflection
Effect Binaries from Optical Surveys (EREBOS) project, which aims to find new
eclipsing sdB+dM binaries (HW Vir systems) and increase the small sample of
studied systems. In addition to the primary eclipse, which is in excess of
$\sim$5 magnitudes in the optical, the light curve also shows features typical
for other HW Vir binaries such as a secondary eclipse and strong reflection
effect from the irradiated, cool companion. The orbital period is 0.127037 d
($\sim$3 hr), falling right at the peak of the orbital period distribution of
known HW Vir systems. Analysis of our time-series spectroscopy yields a radial
velocity semi-amplitude of $K_{\rm sdB}=100.0\pm2.0\,{\rm km\,s}^{-1}$, which
is amongst the fastest line-of-sight velocities found to date for an HW Vir
binary. State-of-the-art atmospheric models that account for deviations from
local thermodynamic equilibrium are used to determine the atmospheric
parameters of the sdB. Although we cannot claim a unique light curve modeling
solution, the best-fitting model has an sdB mass of $M_{\rm sdB} =
0.47\pm0.03\,M_{\odot}$ and a companion mass of $M_{\rm dM} =
0.18\pm0.01\,M_{\odot}$. The radius of the companion appears to be inflated
relative to theoretical mass-radius relationships, consistent with other known
HW Vir binaries. Additionally, the M dwarf is one of the most massive found to
date amongst this type of binary.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'We present time-series spectroscopy and photometry of Gaia DR2\n6097540197980557440, a new deeply-eclipsing hot subdwarf B (sdB) + M dwarf (dM)\nbinary. We discovered this object during the course of the Eclipsing Reflection\nEffect Binaries from Optical Surveys (EREBOS) project, which aims to find new\neclipsing sdB+dM binaries (HW Vir systems) and increase the small sample of\nstudied systems. In addition to the primary eclipse, which is in excess of\n$\\sim$5 magnitudes in the optical, the light curve also shows features typical\nfor other HW Vir binaries such as a secondary eclipse and strong reflection\neffect from the irradiated, cool companion. The orbital period is 0.127037 d\n($\\sim$3 hr), falling right at the peak of the orbital period distribution of\nknown HW Vir systems. Analysis of our time-series spectroscopy yields a radial\nvelocity semi-amplitude of $K_{\\rm sdB}=100.0\\pm2.0\\,{\\rm km\\,s}^{-1}$, which\nis amongst the fastest line-of-sight velocities found to date for an HW Vir\nbinary. State-of-the-art atmospheric models that account for deviations from\nlocal thermodynamic equilibrium are used to determine the atmospheric\nparameters of the sdB. Although we cannot claim a unique light curve modeling\nsolution, the best-fitting model has an sdB mass of $M_{\\rm sdB} =\n0.47\\pm0.03\\,M_{\\odot}$ and a companion mass of $M_{\\rm dM} =\n0.18\\pm0.01\\,M_{\\odot}$. The radius of the companion appears to be inflated\nrelative to theoretical mass-radius relationships, consistent with other known\nHW Vir binaries. Additionally, the M dwarf is one of the most massive found to\ndate amongst this type of binary.'}","[{'name': 'Kyle A. Corcoran'}, {'name': 'Brad N. Barlow'}, {'name': 'Veronika Schaffenroth'}, {'name': 'Uli Heber'}, {'name': 'Stephen Walser'}, {'name': 'Andreas Irgang'}]",{'name': 'Andreas Irgang'},Andreas Irgang,"[{'href': 'http://arxiv.org/abs/2106.08328v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.08328v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'astro-ph.SR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'astro-ph.SR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]","15 pages, 9 figures, accepted for publication by ApJ",,
http://arxiv.org/abs/2106.08361v1,True,http://arxiv.org/abs/2106.08361v1,2021-06-15T18:15:26Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=15, tm_hour=18, tm_min=15, tm_sec=26, tm_wday=1, tm_yday=166, tm_isdst=0)",2021-06-15T18:15:26Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=15, tm_hour=18, tm_min=15, tm_sec=26, tm_wday=1, tm_yday=166, tm_isdst=0)",Adversarial Attacks on Deep Models for Financial Transaction Records,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Adversarial Attacks on Deep Models for Financial Transaction Records'}","Machine learning models using transaction records as inputs are popular among
financial institutions. The most efficient models use deep-learning
architectures similar to those in the NLP community, posing a challenge due to
their tremendous number of parameters and limited robustness. In particular,
deep-learning models are vulnerable to adversarial attacks: a little change in
the input harms the model's output.
  In this work, we examine adversarial attacks on transaction records data and
defences from these attacks. The transaction records data have a different
structure than the canonical NLP or time series data, as neighbouring records
are less connected than words in sentences, and each record consists of both
discrete merchant code and continuous transaction amount. We consider a
black-box attack scenario, where the attack doesn't know the true decision
model, and pay special attention to adding transaction tokens to the end of a
sequence. These limitations provide more realistic scenario, previously
unexplored in NLP world.
  The proposed adversarial attacks and the respective defences demonstrate
remarkable performance using relevant datasets from the financial industry. Our
results show that a couple of generated transactions are sufficient to fool a
deep-learning model. Further, we improve model robustness via adversarial
training or separate adversarial examples detection. This work shows that
embedding protection from adversarial attacks improves model robustness,
allowing a wider adoption of deep models for transaction records in banking and
finance.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': ""Machine learning models using transaction records as inputs are popular among\nfinancial institutions. The most efficient models use deep-learning\narchitectures similar to those in the NLP community, posing a challenge due to\ntheir tremendous number of parameters and limited robustness. In particular,\ndeep-learning models are vulnerable to adversarial attacks: a little change in\nthe input harms the model's output.\n  In this work, we examine adversarial attacks on transaction records data and\ndefences from these attacks. The transaction records data have a different\nstructure than the canonical NLP or time series data, as neighbouring records\nare less connected than words in sentences, and each record consists of both\ndiscrete merchant code and continuous transaction amount. We consider a\nblack-box attack scenario, where the attack doesn't know the true decision\nmodel, and pay special attention to adding transaction tokens to the end of a\nsequence. These limitations provide more realistic scenario, previously\nunexplored in NLP world.\n  The proposed adversarial attacks and the respective defences demonstrate\nremarkable performance using relevant datasets from the financial industry. Our\nresults show that a couple of generated transactions are sufficient to fool a\ndeep-learning model. Further, we improve model robustness via adversarial\ntraining or separate adversarial examples detection. This work shows that\nembedding protection from adversarial attacks improves model robustness,\nallowing a wider adoption of deep models for transaction records in banking and\nfinance.""}","[{'name': 'Ivan Fursov'}, {'name': 'Matvey Morozov'}, {'name': 'Nina Kaploukhaya'}, {'name': 'Elizaveta Kovtun'}, {'name': 'Rodrigo Rivera-Castro'}, {'name': 'Gleb Gusev'}, {'name': 'Dmitry Babaev'}, {'name': 'Ivan Kireev'}, {'name': 'Alexey Zaytsev'}, {'name': 'Evgeny Burnaev'}]",{'name': 'Evgeny Burnaev'},Evgeny Burnaev,"[{'href': 'http://arxiv.org/abs/2106.08361v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.08361v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-fin.ST', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",,,
http://arxiv.org/abs/2106.08411v1,True,http://arxiv.org/abs/2106.08411v1,2021-06-15T20:03:57Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=15, tm_hour=20, tm_min=3, tm_sec=57, tm_wday=1, tm_yday=166, tm_isdst=0)",2021-06-15T20:03:57Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=15, tm_hour=20, tm_min=3, tm_sec=57, tm_wday=1, tm_yday=166, tm_isdst=0)",Linearized Field Deblending: PSF Photometry for Impatient Astronomers,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Linearized Field Deblending: PSF Photometry for Impatient Astronomers'}","NASA's Kepler, K2 and TESS missions employ Simple Aperture Photometry (SAP)
to derive time-series photometry, where an aperture is estimated for each star,
and pixels containing each star are summed to create a single light curve. This
method is simple, but in crowded fields the derived time-series can be highly
contaminated. The alternate method of fitting a Point Spread Function (PSF) to
the data is able to account for crowding, but is computationally expensive. In
this paper, we present a new approach to extracting photometry from these
time-series missions, which fits the PSF directly, but makes simplifying
assumptions in order to greatly reduce the computation expense. Our method
fixes the scene of the field in each image, estimates the PSF shape of the
instrument with a linear model, and allows only source flux and position to
vary. We demonstrate that our method is able to separate the photometry from
blended targets in the Kepler dataset that are separated by less than a pixel.
Our method is fast to compute, and fully accounts for uncertainties from
degeneracies due to crowded fields. We name the method described in this work
Linearized Field Deblending (LFD). We demonstrate our method on the false
positive Kepler target \koi. We are able to separate the photometry of the two
sources in the data, and demonstrate the contaminating transiting signal is
consistent with a small, sub-stellar companion with a radius of $2.67R_{jup}$
($0.27R_{sol}$). Our method is equally applicable to extracting photometry from
NASA's TESS mission.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': ""NASA's Kepler, K2 and TESS missions employ Simple Aperture Photometry (SAP)\nto derive time-series photometry, where an aperture is estimated for each star,\nand pixels containing each star are summed to create a single light curve. This\nmethod is simple, but in crowded fields the derived time-series can be highly\ncontaminated. The alternate method of fitting a Point Spread Function (PSF) to\nthe data is able to account for crowding, but is computationally expensive. In\nthis paper, we present a new approach to extracting photometry from these\ntime-series missions, which fits the PSF directly, but makes simplifying\nassumptions in order to greatly reduce the computation expense. Our method\nfixes the scene of the field in each image, estimates the PSF shape of the\ninstrument with a linear model, and allows only source flux and position to\nvary. We demonstrate that our method is able to separate the photometry from\nblended targets in the Kepler dataset that are separated by less than a pixel.\nOur method is fast to compute, and fully accounts for uncertainties from\ndegeneracies due to crowded fields. We name the method described in this work\nLinearized Field Deblending (LFD). We demonstrate our method on the false\npositive Kepler target \\koi. We are able to separate the photometry of the two\nsources in the data, and demonstrate the contaminating transiting signal is\nconsistent with a small, sub-stellar companion with a radius of $2.67R_{jup}$\n($0.27R_{sol}$). Our method is equally applicable to extracting photometry from\nNASA's TESS mission.""}","[{'name': 'Christina Hedges'}, {'name': 'Rodrigo Luger'}, {'name': 'Jorge Martinez Palomera'}, {'name': 'Jessie Dotson'}, {'name': 'Geert Barentsen'}]",{'name': 'Geert Barentsen'},Geert Barentsen,"[{'href': 'http://arxiv.org/abs/2106.08411v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.08411v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'astro-ph.IM', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'astro-ph.IM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'astro-ph.EP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]","22 Pages, 9 Figures",,
http://arxiv.org/abs/2106.08420v2,True,http://arxiv.org/abs/2106.08420v2,2021-06-22T10:41:07Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=22, tm_hour=10, tm_min=41, tm_sec=7, tm_wday=1, tm_yday=173, tm_isdst=0)",2021-06-15T20:24:32Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=15, tm_hour=20, tm_min=24, tm_sec=32, tm_wday=1, tm_yday=166, tm_isdst=0)",Time Series Momentum Predictability via Dynamic Binary Classification,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Time Series Momentum Predictability via Dynamic Binary Classification'}","Time series momentum strategies are widely applied in the quantitative
financial industry and its academic research has grown rapidly since the work
of Moskowitz, Ooi and Pedersen (2012). However, trading signals are usually
obtained via simple observation of past return measurements. In this article we
study the benefits of incorporating dynamic econometric models to sequentially
learn the time-varying importance of different look-back periods for individual
assets. By the use of a dynamic binary classifier model, the investor is able
to switch between time-varying or constant relations between past momentum and
future returns, dynamically combining different look-back periods and improving
trading signals accuracy and portfolio performance. Using data from 56 future
contracts we show that a mean-variance investor will be willing to pay a
considerable managment fee to switch from the traditional naive time series
momentum strategy to the dynamic classifier approach.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Time series momentum strategies are widely applied in the quantitative\nfinancial industry and its academic research has grown rapidly since the work\nof Moskowitz, Ooi and Pedersen (2012). However, trading signals are usually\nobtained via simple observation of past return measurements. In this article we\nstudy the benefits of incorporating dynamic econometric models to sequentially\nlearn the time-varying importance of different look-back periods for individual\nassets. By the use of a dynamic binary classifier model, the investor is able\nto switch between time-varying or constant relations between past momentum and\nfuture returns, dynamically combining different look-back periods and improving\ntrading signals accuracy and portfolio performance. Using data from 56 future\ncontracts we show that a mean-variance investor will be willing to pay a\nconsiderable managment fee to switch from the traditional naive time series\nmomentum strategy to the dynamic classifier approach.'}","[{'name': 'Bruno P. C. Levy'}, {'name': 'Hedibert F. Lopes'}]",{'name': 'Hedibert F. Lopes'},Hedibert F. Lopes,"[{'href': 'http://arxiv.org/abs/2106.08420v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.08420v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'q-fin.ST', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'q-fin.ST', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",,,
http://arxiv.org/abs/2106.08452v1,True,http://arxiv.org/abs/2106.08452v1,2021-06-15T21:51:47Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=15, tm_hour=21, tm_min=51, tm_sec=47, tm_wday=1, tm_yday=166, tm_isdst=0)",2021-06-15T21:51:47Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=15, tm_hour=21, tm_min=51, tm_sec=47, tm_wday=1, tm_yday=166, tm_isdst=0)",Deep Neural Networks for Approximating Stream Reasoning with C-SPARQL,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Deep Neural Networks for Approximating Stream Reasoning with C-SPARQL'}","The amount of information produced, whether by newspapers, blogs and social
networks, or by monitoring systems, is increasing rapidly. Processing all this
data in real-time, while taking into consideration advanced knowledge about the
problem domain, is challenging, but required in scenarios where assessing
potential risks in a timely fashion is critical. C-SPARQL, a language for
continuous queries over streams of RDF data, is one of the more prominent
approaches in stream reasoning that provides such continuous inference
capabilities over dynamic data that go beyond mere stream processing. However,
it has been shown that, in the presence of huge amounts of data, C-SPARQL may
not be able to answer queries in time, in particular when the frequency of
incoming data is higher than the time required for reasoning with that data. In
this paper, we investigate whether reasoning with C-SPARQL can be approximated
using Recurrent Neural Networks and Convolutional Neural Networks, two neural
network architectures that have been shown to be well-suited for time series
forecasting and time series classification, to leverage on their higher
processing speed once the network has been trained. We consider a variety of
different kinds of queries and obtain overall positive results with high
accuracies while improving processing time often by several orders of
magnitude.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'The amount of information produced, whether by newspapers, blogs and social\nnetworks, or by monitoring systems, is increasing rapidly. Processing all this\ndata in real-time, while taking into consideration advanced knowledge about the\nproblem domain, is challenging, but required in scenarios where assessing\npotential risks in a timely fashion is critical. C-SPARQL, a language for\ncontinuous queries over streams of RDF data, is one of the more prominent\napproaches in stream reasoning that provides such continuous inference\ncapabilities over dynamic data that go beyond mere stream processing. However,\nit has been shown that, in the presence of huge amounts of data, C-SPARQL may\nnot be able to answer queries in time, in particular when the frequency of\nincoming data is higher than the time required for reasoning with that data. In\nthis paper, we investigate whether reasoning with C-SPARQL can be approximated\nusing Recurrent Neural Networks and Convolutional Neural Networks, two neural\nnetwork architectures that have been shown to be well-suited for time series\nforecasting and time series classification, to leverage on their higher\nprocessing speed once the network has been trained. We consider a variety of\ndifferent kinds of queries and obtain overall positive results with high\naccuracies while improving processing time often by several orders of\nmagnitude.'}","[{'name': 'Ricardo Ferreira'}, {'name': 'Carolina Lopes'}, {'name': 'Ricardo Gon√ßalves'}, {'name': 'Matthias Knorr'}, {'name': 'Ludwig Krippahl'}, {'name': 'Jo√£o Leite'}]",{'name': 'Jo√£o Leite'},Jo√£o Leite,"[{'href': 'http://arxiv.org/abs/2106.08452v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.08452v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]","Accepted at the 20th EPIA Conference on Artificial Intelligence, EPIA
  2021",,
http://arxiv.org/abs/2106.08457v1,True,http://arxiv.org/abs/2106.08457v1,2021-06-15T22:06:12Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=15, tm_hour=22, tm_min=6, tm_sec=12, tm_wday=1, tm_yday=166, tm_isdst=0)",2021-06-15T22:06:12Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=15, tm_hour=22, tm_min=6, tm_sec=12, tm_wday=1, tm_yday=166, tm_isdst=0)",Faster than LASER -- Towards Stream Reasoning with Deep Neural Networks,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Faster than LASER -- Towards Stream Reasoning with Deep Neural Networks'}","With the constant increase of available data in various domains, such as the
Internet of Things, Social Networks or Smart Cities, it has become fundamental
that agents are able to process and reason with such data in real time. Whereas
reasoning over time-annotated data with background knowledge may be
challenging, due to the volume and velocity in which such data is being
produced, such complex reasoning is necessary in scenarios where agents need to
discover potential problems and this cannot be done with simple stream
processing techniques. Stream Reasoners aim at bridging this gap between
reasoning and stream processing and LASER is such a stream reasoner designed to
analyse and perform complex reasoning over streams of data. It is based on
LARS, a rule-based logical language extending Answer Set Programming, and it
has shown better runtime results than other state-of-the-art stream reasoning
systems. Nevertheless, for high levels of data throughput even LASER may be
unable to compute answers in a timely fashion. In this paper, we study whether
Convolutional and Recurrent Neural Networks, which have shown to be
particularly well-suited for time series forecasting and classification, can be
trained to approximate reasoning with LASER, so that agents can benefit from
their high processing speed.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'With the constant increase of available data in various domains, such as the\nInternet of Things, Social Networks or Smart Cities, it has become fundamental\nthat agents are able to process and reason with such data in real time. Whereas\nreasoning over time-annotated data with background knowledge may be\nchallenging, due to the volume and velocity in which such data is being\nproduced, such complex reasoning is necessary in scenarios where agents need to\ndiscover potential problems and this cannot be done with simple stream\nprocessing techniques. Stream Reasoners aim at bridging this gap between\nreasoning and stream processing and LASER is such a stream reasoner designed to\nanalyse and perform complex reasoning over streams of data. It is based on\nLARS, a rule-based logical language extending Answer Set Programming, and it\nhas shown better runtime results than other state-of-the-art stream reasoning\nsystems. Nevertheless, for high levels of data throughput even LASER may be\nunable to compute answers in a timely fashion. In this paper, we study whether\nConvolutional and Recurrent Neural Networks, which have shown to be\nparticularly well-suited for time series forecasting and classification, can be\ntrained to approximate reasoning with LASER, so that agents can benefit from\ntheir high processing speed.'}","[{'name': 'Jo√£o Ferreira'}, {'name': 'Diogo Lavado'}, {'name': 'Ricardo Gon√ßalves'}, {'name': 'Matthias Knorr'}, {'name': 'Ludwig Krippahl'}, {'name': 'Jo√£o Leite'}]",{'name': 'Jo√£o Leite'},Jo√£o Leite,"[{'href': 'http://arxiv.org/abs/2106.08457v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.08457v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",Extended version of EPIA 21 paper,,
http://arxiv.org/abs/2106.08531v1,True,http://arxiv.org/abs/2106.08531v1,2021-06-16T03:01:53Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=16, tm_hour=3, tm_min=1, tm_sec=53, tm_wday=2, tm_yday=167, tm_isdst=0)",2021-06-16T03:01:53Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=16, tm_hour=3, tm_min=1, tm_sec=53, tm_wday=2, tm_yday=167, tm_isdst=0)","Latent Representation in Human-Robot Interaction with Explicit
  Consideration of Periodic Dynamics","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Latent Representation in Human-Robot Interaction with Explicit\n  Consideration of Periodic Dynamics'}","This paper presents a new data-driven framework for analyzing periodic
physical human-robot interaction (pHRI) in latent state space. To elaborate
human understanding and/or robot control during pHRI, the model representing
pHRI is critical. Recent developments of deep learning technologies would
enable us to learn such a model from a dataset collected from the actual pHRI.
Our framework is developed based on variational recurrent neural network
(VRNN), which can inherently handle time-series data like one pHRI generates.
This paper modifies VRNN in order to include the latent dynamics from robot to
human explicitly. In addition, to analyze periodic motions like walking, we
integrate a new recurrent network based on reservoir computing (RC), which has
random and fixed connections between numerous neurons, with VRNN. By augmenting
RC into complex domain, periodic behavior can be represented as the phase
rotation in complex domain without decaying the amplitude. For verification of
the proposed framework, a rope-rotation/swinging experiment was analyzed. The
proposed framework, trained on the dataset collected from the experiment,
achieved the latent state space where the differences in periodic motions can
be distinguished. Such a well-distinguished space yielded the best prediction
accuracy of the human observations and the robot actions. The attached video
can be seen in youtube: https://youtu.be/umn0MVcIpsY","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'This paper presents a new data-driven framework for analyzing periodic\nphysical human-robot interaction (pHRI) in latent state space. To elaborate\nhuman understanding and/or robot control during pHRI, the model representing\npHRI is critical. Recent developments of deep learning technologies would\nenable us to learn such a model from a dataset collected from the actual pHRI.\nOur framework is developed based on variational recurrent neural network\n(VRNN), which can inherently handle time-series data like one pHRI generates.\nThis paper modifies VRNN in order to include the latent dynamics from robot to\nhuman explicitly. In addition, to analyze periodic motions like walking, we\nintegrate a new recurrent network based on reservoir computing (RC), which has\nrandom and fixed connections between numerous neurons, with VRNN. By augmenting\nRC into complex domain, periodic behavior can be represented as the phase\nrotation in complex domain without decaying the amplitude. For verification of\nthe proposed framework, a rope-rotation/swinging experiment was analyzed. The\nproposed framework, trained on the dataset collected from the experiment,\nachieved the latent state space where the differences in periodic motions can\nbe distinguished. Such a well-distinguished space yielded the best prediction\naccuracy of the human observations and the robot actions. The attached video\ncan be seen in youtube: https://youtu.be/umn0MVcIpsY'}","[{'name': 'Taisuke Kobayashi'}, {'name': 'Shingo Murata'}, {'name': 'Tetsunari Inamura'}]",{'name': 'Tetsunari Inamura'},Tetsunari Inamura,"[{'href': 'http://arxiv.org/abs/2106.08531v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.08531v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]","10 pages, 10 figures",,
http://arxiv.org/abs/2106.08564v1,True,http://arxiv.org/abs/2106.08564v1,2021-06-16T06:00:49Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=16, tm_hour=6, tm_min=0, tm_sec=49, tm_wday=2, tm_yday=167, tm_isdst=0)",2021-06-16T06:00:49Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=16, tm_hour=6, tm_min=0, tm_sec=49, tm_wday=2, tm_yday=167, tm_isdst=0)","Adaptive Visibility Graph Neural Network and its Application in
  Modulation Classification","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Adaptive Visibility Graph Neural Network and its Application in\n  Modulation Classification'}","Our digital world is full of time series and graphs which capture the various
aspects of many complex systems. Traditionally, there are respective methods in
processing these two different types of data, e.g., Recurrent Neural Network
(RNN) and Graph Neural Network (GNN), while in recent years, time series could
be mapped to graphs by using the techniques such as Visibility Graph (VG), so
that researchers can use graph algorithms to mine the knowledge in time series.
Such mapping methods establish a bridge between time series and graphs, and
have high potential to facilitate the analysis of various real-world time
series. However, the VG method and its variants are just based on fixed rules
and thus lack of flexibility, largely limiting their application in reality. In
this paper, we propose an Adaptive Visibility Graph (AVG) algorithm that can
adaptively map time series into graphs, based on which we further establish an
end-to-end classification framework AVGNet, by utilizing GNN model DiffPool as
the classifier. We then adopt AVGNet for radio signal modulation classification
which is an important task in the field of wireless communication. The
simulations validate that AVGNet outperforms a series of advanced deep learning
methods, achieving the state-of-the-art performance in this task.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Our digital world is full of time series and graphs which capture the various\naspects of many complex systems. Traditionally, there are respective methods in\nprocessing these two different types of data, e.g., Recurrent Neural Network\n(RNN) and Graph Neural Network (GNN), while in recent years, time series could\nbe mapped to graphs by using the techniques such as Visibility Graph (VG), so\nthat researchers can use graph algorithms to mine the knowledge in time series.\nSuch mapping methods establish a bridge between time series and graphs, and\nhave high potential to facilitate the analysis of various real-world time\nseries. However, the VG method and its variants are just based on fixed rules\nand thus lack of flexibility, largely limiting their application in reality. In\nthis paper, we propose an Adaptive Visibility Graph (AVG) algorithm that can\nadaptively map time series into graphs, based on which we further establish an\nend-to-end classification framework AVGNet, by utilizing GNN model DiffPool as\nthe classifier. We then adopt AVGNet for radio signal modulation classification\nwhich is an important task in the field of wireless communication. The\nsimulations validate that AVGNet outperforms a series of advanced deep learning\nmethods, achieving the state-of-the-art performance in this task.'}","[{'name': 'Qi Xuan'}, {'name': 'Kunfeng Qiu'}, {'name': 'Jinchao Zhou'}, {'name': 'Zhuangzhi Chen'}, {'name': 'Dongwei Xu'}, {'name': 'Shilian Zheng'}, {'name': 'Xiaoniu Yang'}]",{'name': 'Xiaoniu Yang'},Xiaoniu Yang,"[{'href': 'http://arxiv.org/abs/2106.08564v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.08564v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'eess.SP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",,,
http://arxiv.org/abs/2106.08623v1,True,http://arxiv.org/abs/2106.08623v1,2021-06-16T08:28:23Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=16, tm_hour=8, tm_min=28, tm_sec=23, tm_wday=2, tm_yday=167, tm_isdst=0)",2021-06-16T08:28:23Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=16, tm_hour=8, tm_min=28, tm_sec=23, tm_wday=2, tm_yday=167, tm_isdst=0)","Using Mutual Information to measure Time-lags from non-linear processes
  in Astronomy","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Using Mutual Information to measure Time-lags from non-linear processes\n  in Astronomy'}","Measuring time lags between time-series or lighcurves at different
wavelengths from a variable or transient source in astronomy is an essential
probe of physical mechanisms causing multiwavelength variability. Time-lags are
typically quantified using discrete correlation functions (DCF) which are
appropriate for linear relationships. However, in variable sources like X-ray
binaries, active galactic nuclei (AGN) and other accreting systems, the
radiative processes and the resulting multiwavelength lightcurves often have
non-linear relationships. For such systems it is more appropriate to use
non-linear information-theoretic measures of causation like mutual information,
routinely used in other disciplines. We demonstrate with toy models loopholes
of using the standard DCF & show improvements when using the mutual information
correlation function (MICF). For non-linear correlations, the latter accurately
& sharply identifies the lag components as opposed to the DCF which can be
erroneous. Following that we apply the MICF to the multiwavelength lightcurves
of AGN NGC 4593. We find that X-ray fluxes lead UVW2 fluxes by ~0.2 days,
closer to model predictions from reprocessing by the accretion disk than the
DCF estimate. The uncertainties with the current lightcurves are too large
though to rule out -ve lags. Additionally, we find another delay component at
~-1 day i.e. UVW2 leading X-rays consistent with inward propagating
fluctuations in the accretion disk scenario. This is not detected by the DCF.
Keeping in mind the non-linear relation between X-ray & UVW2, this is worthy of
further theoretical investigation. From both toy models & real observations, it
is clear that the mutual information based estimator is highly sensitive to
complex non-linear correlations. With sufficiently high temporal resolution, we
will precisely detect each of the lag features corresponding to these
correlations.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Measuring time lags between time-series or lighcurves at different\nwavelengths from a variable or transient source in astronomy is an essential\nprobe of physical mechanisms causing multiwavelength variability. Time-lags are\ntypically quantified using discrete correlation functions (DCF) which are\nappropriate for linear relationships. However, in variable sources like X-ray\nbinaries, active galactic nuclei (AGN) and other accreting systems, the\nradiative processes and the resulting multiwavelength lightcurves often have\nnon-linear relationships. For such systems it is more appropriate to use\nnon-linear information-theoretic measures of causation like mutual information,\nroutinely used in other disciplines. We demonstrate with toy models loopholes\nof using the standard DCF & show improvements when using the mutual information\ncorrelation function (MICF). For non-linear correlations, the latter accurately\n& sharply identifies the lag components as opposed to the DCF which can be\nerroneous. Following that we apply the MICF to the multiwavelength lightcurves\nof AGN NGC 4593. We find that X-ray fluxes lead UVW2 fluxes by ~0.2 days,\ncloser to model predictions from reprocessing by the accretion disk than the\nDCF estimate. The uncertainties with the current lightcurves are too large\nthough to rule out -ve lags. Additionally, we find another delay component at\n~-1 day i.e. UVW2 leading X-rays consistent with inward propagating\nfluctuations in the accretion disk scenario. This is not detected by the DCF.\nKeeping in mind the non-linear relation between X-ray & UVW2, this is worthy of\nfurther theoretical investigation. From both toy models & real observations, it\nis clear that the mutual information based estimator is highly sensitive to\ncomplex non-linear correlations. With sufficiently high temporal resolution, we\nwill precisely detect each of the lag features corresponding to these\ncorrelations.'}","[{'name': 'Nachiketa Chakraborty'}, {'name': 'Peter Jan van Leeuwen'}]",{'name': 'Peter Jan van Leeuwen'},Peter Jan van Leeuwen,"[{'href': 'http://arxiv.org/abs/2106.08623v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.08623v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'astro-ph.IM', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'astro-ph.IM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'astro-ph.HE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.data-an', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]","13 pages, 6 figures",,
http://arxiv.org/abs/2106.08781v1,True,http://arxiv.org/abs/2106.08781v1,2021-06-16T13:41:15Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=16, tm_hour=13, tm_min=41, tm_sec=15, tm_wday=2, tm_yday=167, tm_isdst=0)",2021-06-16T13:41:15Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=16, tm_hour=13, tm_min=41, tm_sec=15, tm_wday=2, tm_yday=167, tm_isdst=0)","Magnetic helicity and energy budget around large confined and eruptive
  solar flares","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Magnetic helicity and energy budget around large confined and eruptive\n  solar flares'}","We investigate the coronal magnetic energy and helicity budgets of ten solar
ARs, around the times of large flares. In particular, we are interested in a
possible relation of the derived quantities to the particular type of the
flares that the AR produces, i.e., whether they are associated with a CME or
they are confined. Using an optimization approach, we employ time series of 3D
nonlinear force-free magnetic field models of ten ARs, covering a time span of
several hours around the time of occurrence of large solar flares (GOES class
M1.0 and larger). We subsequently compute the 3D magnetic vector potentials
associated to the model 3D coronal magnetic field using a finite-volume method.
This allows us to correspondingly compute the coronal magnetic energy and
helicity budgets, as well as related (intensive) quantities such as the
relative contribution of free magnetic energy, $E_{\mathrm{F}}/{E}$ (energy
ratio), the fraction of non-potential (current-carrying) helicity,
$|H_{\mathrm{J}}|/|{H_{V}}|$ (helicity ratio), and the normalized
current-carrying helicity, $|H_{\mathrm{J}}|/{\phi^{\prime}}^{2}$. The total
energy and helicity budgets of flare-productive ARs (extensive parameters)
cover a broad range of magnitudes, with no obvious relation to the eruptive
potential of the individual ARs, i.e., whether or not a CME is produced in
association with the flare. The intensive eruptivity proxies,
$E_{\mathrm{F}}/{E}$ and $|H_{\mathrm{J}}|/|{H_{V}}|$, and
$|H_{\mathrm{J}}|/{\phi^{\prime}}^{2}$, however, seem to be distinctly
different for ARs that produced CME-associated large flares compared to those
which produced confined flares. For the majority of ARs in our sample, we are
able to identify characteristic pre-flare magnitudes of the intensive
quantities, clearly associated to subsequent CME-productivity.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'We investigate the coronal magnetic energy and helicity budgets of ten solar\nARs, around the times of large flares. In particular, we are interested in a\npossible relation of the derived quantities to the particular type of the\nflares that the AR produces, i.e., whether they are associated with a CME or\nthey are confined. Using an optimization approach, we employ time series of 3D\nnonlinear force-free magnetic field models of ten ARs, covering a time span of\nseveral hours around the time of occurrence of large solar flares (GOES class\nM1.0 and larger). We subsequently compute the 3D magnetic vector potentials\nassociated to the model 3D coronal magnetic field using a finite-volume method.\nThis allows us to correspondingly compute the coronal magnetic energy and\nhelicity budgets, as well as related (intensive) quantities such as the\nrelative contribution of free magnetic energy, $E_{\\mathrm{F}}/{E}$ (energy\nratio), the fraction of non-potential (current-carrying) helicity,\n$|H_{\\mathrm{J}}|/|{H_{V}}|$ (helicity ratio), and the normalized\ncurrent-carrying helicity, $|H_{\\mathrm{J}}|/{\\phi^{\\prime}}^{2}$. The total\nenergy and helicity budgets of flare-productive ARs (extensive parameters)\ncover a broad range of magnitudes, with no obvious relation to the eruptive\npotential of the individual ARs, i.e., whether or not a CME is produced in\nassociation with the flare. The intensive eruptivity proxies,\n$E_{\\mathrm{F}}/{E}$ and $|H_{\\mathrm{J}}|/|{H_{V}}|$, and\n$|H_{\\mathrm{J}}|/{\\phi^{\\prime}}^{2}$, however, seem to be distinctly\ndifferent for ARs that produced CME-associated large flares compared to those\nwhich produced confined flares. For the majority of ARs in our sample, we are\nable to identify characteristic pre-flare magnitudes of the intensive\nquantities, clearly associated to subsequent CME-productivity.'}","[{'name': 'Manu Gupta'}, {'name': 'J. K. Thalmann'}, {'name': 'A. M. Veronig'}]",{'name': 'A. M. Veronig'},A. M. Veronig,"[{'href': 'http://arxiv.org/abs/2106.08781v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.08781v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'astro-ph.SR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'astro-ph.SR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]","Accepted for publication in A & A journal, 19 pages, and 11 figures",,
http://arxiv.org/abs/2106.09053v1,True,http://arxiv.org/abs/2106.09053v1,2021-06-16T18:00:17Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=16, tm_hour=18, tm_min=0, tm_sec=17, tm_wday=2, tm_yday=167, tm_isdst=0)",2021-06-16T18:00:17Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=16, tm_hour=18, tm_min=0, tm_sec=17, tm_wday=2, tm_yday=167, tm_isdst=0)",ASASSN-14lp: two possible solutions for the observed UV suppression,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'ASASSN-14lp: two possible solutions for the observed UV suppression'}","We test the adequacy of ultraviolet (UV) spectra for characterizing the outer
structure of Type Ia supernova (SN) ejecta. For this purpose, we perform
spectroscopic analysis for ASASSN-14lp, a normal SN Ia showing low continuum in
the mid-UV regime. To explain the strong UV suppression, two possible origins
have been investigated by mapping the chemical profiles over a significant part
of their ejecta. We fit the spectral time series with mid-UV coverage obtained
before and around maximum light by HST, supplemented with ground-based optical
observations for the earliest epochs. The synthetic spectra are calculated with
the one dimensional MC radiative-transfer code TARDIS from self-consistent
ejecta models. Among several physical parameters, we constrain the abundance
profiles of nine chemical elements. We find that a distribution of $^{56}$Ni
(and other iron-group elements) that extends toward the highest velocities
reproduces the observed UV flux well. The presence of radioactive material in
the outer layers of the ejecta, if confirmed, implies strong constraints on the
possible explosion scenarios. We investigate the impact of the inferred
$^{56}$Ni distribution on the early light curves with the radiative transfer
code TURTLS, and confront the results with the observed light curves of
ASASSN-14lp. The inferred abundances are not in conflict with the observed
photometry. We also test whether the UV suppression can be reproduced if the
radiation at the photosphere is significantly lower in the UV regime than the
pure Planck function. In this case, solar metallicity might be sufficient
enough at the highest velocities to reproduce the UV suppression.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'We test the adequacy of ultraviolet (UV) spectra for characterizing the outer\nstructure of Type Ia supernova (SN) ejecta. For this purpose, we perform\nspectroscopic analysis for ASASSN-14lp, a normal SN Ia showing low continuum in\nthe mid-UV regime. To explain the strong UV suppression, two possible origins\nhave been investigated by mapping the chemical profiles over a significant part\nof their ejecta. We fit the spectral time series with mid-UV coverage obtained\nbefore and around maximum light by HST, supplemented with ground-based optical\nobservations for the earliest epochs. The synthetic spectra are calculated with\nthe one dimensional MC radiative-transfer code TARDIS from self-consistent\nejecta models. Among several physical parameters, we constrain the abundance\nprofiles of nine chemical elements. We find that a distribution of $^{56}$Ni\n(and other iron-group elements) that extends toward the highest velocities\nreproduces the observed UV flux well. The presence of radioactive material in\nthe outer layers of the ejecta, if confirmed, implies strong constraints on the\npossible explosion scenarios. We investigate the impact of the inferred\n$^{56}$Ni distribution on the early light curves with the radiative transfer\ncode TURTLS, and confront the results with the observed light curves of\nASASSN-14lp. The inferred abundances are not in conflict with the observed\nphotometry. We also test whether the UV suppression can be reproduced if the\nradiation at the photosphere is significantly lower in the UV regime than the\npure Planck function. In this case, solar metallicity might be sufficient\nenough at the highest velocities to reproduce the UV suppression.'}","[{'name': 'Barnab√°s Barna'}, {'name': 'Talytha Pereira'}, {'name': 'Stefan Taubenberger'}, {'name': 'Mark Magee'}, {'name': 'Markus Kromer'}, {'name': 'Wolfgang Kerzendorf'}, {'name': 'Christian Vogl'}, {'name': 'Marc E. Williamson'}, {'name': 'Andreas Fl√∂rs'}, {'name': 'Ulrich M. Noebauer'}, {'name': 'Ryan J. Foley'}, {'name': 'Michele Sasdelli'}, {'name': 'Wolfgang Hillebrandt'}]",{'name': 'Wolfgang Hillebrandt'},Wolfgang Hillebrandt,"[{'href': 'http://arxiv.org/abs/2106.09053v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.09053v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'astro-ph.SR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'astro-ph.SR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]","18 pages, 16 figures, accepted for publication in MNRAS",,
http://arxiv.org/abs/2106.09296v1,True,http://arxiv.org/abs/2106.09296v1,2021-06-17T07:59:15Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=17, tm_hour=7, tm_min=59, tm_sec=15, tm_wday=3, tm_yday=168, tm_isdst=0)",2021-06-17T07:59:15Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=17, tm_hour=7, tm_min=59, tm_sec=15, tm_wday=3, tm_yday=168, tm_isdst=0)","Voice2Series: Reprogramming Acoustic Models for Time Series
  Classification","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Voice2Series: Reprogramming Acoustic Models for Time Series\n  Classification'}","Learning to classify time series with limited data is a practical yet
challenging problem. Current methods are primarily based on hand-designed
feature extraction rules or domain-specific data augmentation. Motivated by the
advances in deep speech processing models and the fact that voice data are
univariate temporal signals, in this paper, we propose Voice2Series (V2S), a
novel end-to-end approach that reprograms acoustic models for time series
classification, through input transformation learning and output label mapping.
Leveraging the representation learning power of a large-scale pre-trained
speech processing model, on 30 different time series tasks we show that V2S
either outperforms or is tied with state-of-the-art methods on 20 tasks, and
improves their average accuracy by 1.84%. We further provide a theoretical
justification of V2S by proving its population risk is upper bounded by the
source risk and a Wasserstein distance accounting for feature alignment via
reprogramming. Our results offer new and effective means to time series
classification.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Learning to classify time series with limited data is a practical yet\nchallenging problem. Current methods are primarily based on hand-designed\nfeature extraction rules or domain-specific data augmentation. Motivated by the\nadvances in deep speech processing models and the fact that voice data are\nunivariate temporal signals, in this paper, we propose Voice2Series (V2S), a\nnovel end-to-end approach that reprograms acoustic models for time series\nclassification, through input transformation learning and output label mapping.\nLeveraging the representation learning power of a large-scale pre-trained\nspeech processing model, on 30 different time series tasks we show that V2S\neither outperforms or is tied with state-of-the-art methods on 20 tasks, and\nimproves their average accuracy by 1.84%. We further provide a theoretical\njustification of V2S by proving its population risk is upper bounded by the\nsource risk and a Wasserstein distance accounting for feature alignment via\nreprogramming. Our results offer new and effective means to time series\nclassification.'}","[{'name': 'Chao-Han Huck Yang'}, {'name': 'Yun-Yun Tsai'}, {'name': 'Pin-Yu Chen'}]",{'name': 'Pin-Yu Chen'},Pin-Yu Chen,"[{'href': 'http://arxiv.org/abs/2106.09296v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.09296v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SD', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'eess.AS', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]","Accepted to ICML 2021, 16 Pages","Proceedings of the 38th International Conference on Machine
  Learning 2021",
http://arxiv.org/abs/2106.09305v1,True,http://arxiv.org/abs/2106.09305v1,2021-06-17T08:15:04Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=17, tm_hour=8, tm_min=15, tm_sec=4, tm_wday=3, tm_yday=168, tm_isdst=0)",2021-06-17T08:15:04Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=17, tm_hour=8, tm_min=15, tm_sec=4, tm_wday=3, tm_yday=168, tm_isdst=0)","Time Series is a Special Sequence: Forecasting with Sample Convolution
  and Interaction","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Time Series is a Special Sequence: Forecasting with Sample Convolution\n  and Interaction'}","Time series is a special type of sequence data, a set of observations
collected at even intervals of time and ordered chronologically. Existing deep
learning techniques use generic sequence models (e.g., recurrent neural
network, Transformer model, or temporal convolutional network) for time series
analysis, which ignore some of its unique properties. For example, the
downsampling of time series data often preserves most of the information in the
data, while this is not true for general sequence data such as text sequence
and DNA sequence. Motivated by the above, in this paper, we propose a novel
neural network architecture and apply it for the time series forecasting
problem, wherein we conduct sample convolution and interaction at multiple
resolutions for temporal modeling. The proposed architecture, namelySCINet,
facilitates extracting features with enhanced predictability. Experimental
results show that SCINet achieves significant prediction accuracy improvement
over existing solutions across various real-world time series forecasting
datasets. In particular, it can achieve high fore-casting accuracy for those
temporal-spatial datasets without using sophisticated spatial modeling
techniques. Our codes and data are presented in the supplemental material.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Time series is a special type of sequence data, a set of observations\ncollected at even intervals of time and ordered chronologically. Existing deep\nlearning techniques use generic sequence models (e.g., recurrent neural\nnetwork, Transformer model, or temporal convolutional network) for time series\nanalysis, which ignore some of its unique properties. For example, the\ndownsampling of time series data often preserves most of the information in the\ndata, while this is not true for general sequence data such as text sequence\nand DNA sequence. Motivated by the above, in this paper, we propose a novel\nneural network architecture and apply it for the time series forecasting\nproblem, wherein we conduct sample convolution and interaction at multiple\nresolutions for temporal modeling. The proposed architecture, namelySCINet,\nfacilitates extracting features with enhanced predictability. Experimental\nresults show that SCINet achieves significant prediction accuracy improvement\nover existing solutions across various real-world time series forecasting\ndatasets. In particular, it can achieve high fore-casting accuracy for those\ntemporal-spatial datasets without using sophisticated spatial modeling\ntechniques. Our codes and data are presented in the supplemental material.'}","[{'name': 'Minhao Liu'}, {'name': 'Ailing Zeng'}, {'name': 'Qiuxia Lai'}, {'name': 'Qiang Xu'}]",{'name': 'Qiang Xu'},Qiang Xu,"[{'href': 'http://arxiv.org/abs/2106.09305v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.09305v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",,,
http://arxiv.org/abs/2106.09327v1,True,http://arxiv.org/abs/2106.09327v1,2021-06-17T08:46:53Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=17, tm_hour=8, tm_min=46, tm_sec=53, tm_wday=3, tm_yday=168, tm_isdst=0)",2021-06-17T08:46:53Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=17, tm_hour=8, tm_min=46, tm_sec=53, tm_wday=3, tm_yday=168, tm_isdst=0)",Minimax Estimation of Partially-Observed Vector AutoRegressions,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Minimax Estimation of Partially-Observed Vector AutoRegressions'}","To understand the behavior of large dynamical systems like transportation
networks, one must often rely on measurements transmitted by a set of sensors,
for instance individual vehicles. Such measurements are likely to be incomplete
and imprecise, which makes it hard to recover the underlying signal of
interest.Hoping to quantify this phenomenon, we study the properties of a
partially-observed state-space model. In our setting, the latent state $X$
follows a high-dimensional Vector AutoRegressive process $X_t = \theta X_{t-1}
+ \varepsilon_t$. Meanwhile, the observations $Y$ are given by a
noise-corrupted random sample from the state $Y_t = \Pi_t X_t + \eta_t$.
Several random sampling mechanisms are studied, allowing us to investigate the
effect of spatial and temporal correlations in the distribution of the sampling
matrices $\Pi_t$.We first prove a lower bound on the minimax estimation error
for the transition matrix $\theta$. We then describe a sparse estimator based
on the Dantzig selector and upper bound its non-asymptotic error, showing that
it achieves the optimal convergence rate for most of our sampling mechanisms.
Numerical experiments on simulated time series validate our theoretical
findings, while an application to open railway data highlights the relevance of
this model for public transport traffic analysis.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'To understand the behavior of large dynamical systems like transportation\nnetworks, one must often rely on measurements transmitted by a set of sensors,\nfor instance individual vehicles. Such measurements are likely to be incomplete\nand imprecise, which makes it hard to recover the underlying signal of\ninterest.Hoping to quantify this phenomenon, we study the properties of a\npartially-observed state-space model. In our setting, the latent state $X$\nfollows a high-dimensional Vector AutoRegressive process $X_t = \\theta X_{t-1}\n+ \\varepsilon_t$. Meanwhile, the observations $Y$ are given by a\nnoise-corrupted random sample from the state $Y_t = \\Pi_t X_t + \\eta_t$.\nSeveral random sampling mechanisms are studied, allowing us to investigate the\neffect of spatial and temporal correlations in the distribution of the sampling\nmatrices $\\Pi_t$.We first prove a lower bound on the minimax estimation error\nfor the transition matrix $\\theta$. We then describe a sparse estimator based\non the Dantzig selector and upper bound its non-asymptotic error, showing that\nit achieves the optimal convergence rate for most of our sampling mechanisms.\nNumerical experiments on simulated time series validate our theoretical\nfindings, while an application to open railway data highlights the relevance of\nthis model for public transport traffic analysis.'}","[{'name': 'Guillaume Dalle'}, {'name': 'Yohann de Castro'}]",{'name': 'Yohann de Castro'},Yohann de Castro,"[{'href': 'http://arxiv.org/abs/2106.09327v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.09327v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'eess.SP', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'eess.SP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.ST', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ME', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.TH', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",,,"ICJ, ECL"
http://arxiv.org/abs/2106.09499v1,True,http://arxiv.org/abs/2106.09499v1,2021-06-17T13:48:57Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=17, tm_hour=13, tm_min=48, tm_sec=57, tm_wday=3, tm_yday=168, tm_isdst=0)",2021-06-17T13:48:57Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=17, tm_hour=13, tm_min=48, tm_sec=57, tm_wday=3, tm_yday=168, tm_isdst=0)",Maximum Entropy Spectral Analysis: a case study,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Maximum Entropy Spectral Analysis: a case study'}","The Maximum Entropy Spectral Analysis (MESA) method, developed by Burg,
provides a powerful tool to perform spectral estimation of a time-series. The
method relies on a Jaynes' maximum entropy principle and provides the means of
inferring the spectrum of a stochastic process in terms of the coefficients of
some autoregressive process AR($p$) of order $p$. A closed form recursive
solution provides an estimate of the autoregressive coefficients as well as of
the order $p$ of the process. We provide a ready-to-use implementation of the
algorithm in the form of a python package \texttt{memspectrum}. We characterize
our implementation by performing a power spectral density analysis on synthetic
data (with known power spectral density) and we compare different criteria for
stopping the recursion. Furthermore, we compare the performance of our code
with the ubiquitous Welch algorithm, using synthetic data generated from the
released spectrum by the LIGO-Virgo collaboration. We find that, when compared
to Welch's method, Burg's method provides a power spectral density (PSD)
estimation with a systematically lower variance and bias. This is particularly
manifest in the case of a little number of data points, making Burg's method
most suitable to work in this regime.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': ""The Maximum Entropy Spectral Analysis (MESA) method, developed by Burg,\nprovides a powerful tool to perform spectral estimation of a time-series. The\nmethod relies on a Jaynes' maximum entropy principle and provides the means of\ninferring the spectrum of a stochastic process in terms of the coefficients of\nsome autoregressive process AR($p$) of order $p$. A closed form recursive\nsolution provides an estimate of the autoregressive coefficients as well as of\nthe order $p$ of the process. We provide a ready-to-use implementation of the\nalgorithm in the form of a python package \\texttt{memspectrum}. We characterize\nour implementation by performing a power spectral density analysis on synthetic\ndata (with known power spectral density) and we compare different criteria for\nstopping the recursion. Furthermore, we compare the performance of our code\nwith the ubiquitous Welch algorithm, using synthetic data generated from the\nreleased spectrum by the LIGO-Virgo collaboration. We find that, when compared\nto Welch's method, Burg's method provides a power spectral density (PSD)\nestimation with a systematically lower variance and bias. This is particularly\nmanifest in the case of a little number of data points, making Burg's method\nmost suitable to work in this regime.""}","[{'name': 'Alessandro Martini'}, {'name': 'Stefano Schmidt'}, {'name': 'Walter Del Pozzo'}]",{'name': 'Walter Del Pozzo'},Walter Del Pozzo,"[{'href': 'http://arxiv.org/abs/2106.09499v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.09499v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'stat.ME', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'stat.ME', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'astro-ph.IM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.data-an', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]","16 pages, 13 figure, submitted to A&A",,
http://arxiv.org/abs/2106.09597v1,True,http://arxiv.org/abs/2106.09597v1,2021-06-17T15:29:25Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=17, tm_hour=15, tm_min=29, tm_sec=25, tm_wday=3, tm_yday=168, tm_isdst=0)",2021-06-17T15:29:25Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=17, tm_hour=15, tm_min=29, tm_sec=25, tm_wday=3, tm_yday=168, tm_isdst=0)","Hierarchical surrogate-based Approximate Bayesian Computation for an
  electric motor test bench","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Hierarchical surrogate-based Approximate Bayesian Computation for an\n  electric motor test bench'}","Inferring parameter distributions of complex industrial systems from noisy
time series data requires methods to deal with the uncertainty of the
underlying data and the used simulation model. Bayesian inference is well
suited for these uncertain inverse problems. Standard methods used to identify
uncertain parameters are Markov Chain Monte Carlo (MCMC) methods with explicit
evaluation of a likelihood function. However, if the likelihood is very
complex, such that its evaluation is computationally expensive, or even unknown
in its explicit form, Approximate Bayesian Computation (ABC) methods provide a
promising alternative. In this work both methods are first applied to
artificially generated data and second on a real world problem, by using data
of an electric motor test bench. We show that both methods are able to infer
the distribution of varying parameters with a Bayesian hierarchical approach.
But the proposed ABC method is computationally much more efficient in order to
achieve results with similar accuracy. We suggest to use summary statistics in
order to reduce the dimension of the data which significantly increases the
efficiency of the algorithm. Further the simulation model is replaced by a
Polynomial Chaos Expansion (PCE) surrogate to speed up model evaluations. We
proof consistency for the proposed surrogate-based ABC method with summary
statistics under mild conditions on the (approximated) forward model.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Inferring parameter distributions of complex industrial systems from noisy\ntime series data requires methods to deal with the uncertainty of the\nunderlying data and the used simulation model. Bayesian inference is well\nsuited for these uncertain inverse problems. Standard methods used to identify\nuncertain parameters are Markov Chain Monte Carlo (MCMC) methods with explicit\nevaluation of a likelihood function. However, if the likelihood is very\ncomplex, such that its evaluation is computationally expensive, or even unknown\nin its explicit form, Approximate Bayesian Computation (ABC) methods provide a\npromising alternative. In this work both methods are first applied to\nartificially generated data and second on a real world problem, by using data\nof an electric motor test bench. We show that both methods are able to infer\nthe distribution of varying parameters with a Bayesian hierarchical approach.\nBut the proposed ABC method is computationally much more efficient in order to\nachieve results with similar accuracy. We suggest to use summary statistics in\norder to reduce the dimension of the data which significantly increases the\nefficiency of the algorithm. Further the simulation model is replaced by a\nPolynomial Chaos Expansion (PCE) surrogate to speed up model evaluations. We\nproof consistency for the proposed surrogate-based ABC method with summary\nstatistics under mild conditions on the (approximated) forward model.'}","[{'name': 'David N. John'}, {'name': 'Livia Stohrer'}, {'name': 'Claudia Schillings'}, {'name': 'Michael Schick'}, {'name': 'Vincent Heuveline'}]",{'name': 'Vincent Heuveline'},Vincent Heuveline,"[{'href': 'http://arxiv.org/abs/2106.09597v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.09597v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'stat.AP', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'stat.AP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.OC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.data-an', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ME', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",,,
http://arxiv.org/abs/2106.09620v1,True,http://arxiv.org/abs/2106.09620v1,2021-06-17T15:56:57Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=17, tm_hour=15, tm_min=56, tm_sec=57, tm_wday=3, tm_yday=168, tm_isdst=0)",2021-06-17T15:56:57Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=17, tm_hour=15, tm_min=56, tm_sec=57, tm_wday=3, tm_yday=168, tm_isdst=0)","Disentangling Identifiable Features from Noisy Data with Structured
  Nonlinear ICA","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Disentangling Identifiable Features from Noisy Data with Structured\n  Nonlinear ICA'}","We introduce a new general identifiable framework for principled
disentanglement referred to as Structured Nonlinear Independent Component
Analysis (SNICA). Our contribution is to extend the identifiability theory of
deep generative models for a very broad class of structured models. While
previous works have shown identifiability for specific classes of time-series
models, our theorems extend this to more general temporal structures as well as
to models with more complex structures such as spatial dependencies. In
particular, we establish the major result that identifiability for this
framework holds even in the presence of noise of unknown distribution. The
SNICA setting therefore subsumes all the existing nonlinear ICA models for
time-series and also allows for new much richer identifiable models. Finally,
as an example of our framework's flexibility, we introduce the first nonlinear
ICA model for time-series that combines the following very useful properties:
it accounts for both nonstationarity and autocorrelation in a fully
unsupervised setting; performs dimensionality reduction; models hidden states;
and enables principled estimation and inference by variational
maximum-likelihood.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': ""We introduce a new general identifiable framework for principled\ndisentanglement referred to as Structured Nonlinear Independent Component\nAnalysis (SNICA). Our contribution is to extend the identifiability theory of\ndeep generative models for a very broad class of structured models. While\nprevious works have shown identifiability for specific classes of time-series\nmodels, our theorems extend this to more general temporal structures as well as\nto models with more complex structures such as spatial dependencies. In\nparticular, we establish the major result that identifiability for this\nframework holds even in the presence of noise of unknown distribution. The\nSNICA setting therefore subsumes all the existing nonlinear ICA models for\ntime-series and also allows for new much richer identifiable models. Finally,\nas an example of our framework's flexibility, we introduce the first nonlinear\nICA model for time-series that combines the following very useful properties:\nit accounts for both nonstationarity and autocorrelation in a fully\nunsupervised setting; performs dimensionality reduction; models hidden states;\nand enables principled estimation and inference by variational\nmaximum-likelihood.""}","[{'name': 'Hermanni H√§lv√§'}, {'name': 'Sylvain Le Corff'}, {'name': 'Luc Leh√©ricy'}, {'name': 'Jonathan So'}, {'name': 'Yongjie Zhu'}, {'name': 'Elisabeth Gassiat'}, {'name': 'Aapo Hyvarinen'}]",{'name': 'Aapo Hyvarinen'},Aapo Hyvarinen,"[{'href': 'http://arxiv.org/abs/2106.09620v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.09620v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",preprint,,
http://arxiv.org/abs/2106.09636v1,True,http://arxiv.org/abs/2106.09636v1,2021-06-17T16:32:47Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=17, tm_hour=16, tm_min=32, tm_sec=47, tm_wday=3, tm_yday=168, tm_isdst=0)",2021-06-17T16:32:47Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=17, tm_hour=16, tm_min=32, tm_sec=47, tm_wday=3, tm_yday=168, tm_isdst=0)","Multi-Modal Prototype Learning for Interpretable Multivariable Time
  Series Classification","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Multi-Modal Prototype Learning for Interpretable Multivariable Time\n  Series Classification'}","Multivariable time series classification problems are increasing in
prevalence and complexity in a variety of domains, such as biology and finance.
While deep learning methods are an effective tool for these problems, they
often lack interpretability. In this work, we propose a novel modular prototype
learning framework for multivariable time series classification. In the first
stage of our framework, encoders extract features from each variable
independently. Prototype layers identify single-variable prototypes in the
resulting feature spaces. The next stage of our framework represents the
multivariable time series sample points in terms of their similarity to these
single-variable prototypes. This results in an inherently interpretable
representation of multivariable patterns, on which prototype learning is
applied to extract representative examples i.e. multivariable prototypes. Our
framework is thus able to explicitly identify both informative patterns in the
individual variables, as well as the relationships between the variables. We
validate our framework on a simulated dataset with embedded patterns, as well
as a real human activity recognition problem. Our framework attains comparable
or superior classification performance to existing time series classification
methods on these tasks. On the simulated dataset, we find that our model
returns interpretations consistent with the embedded patterns. Moreover, the
interpretations learned on the activity recognition dataset align with domain
knowledge.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Multivariable time series classification problems are increasing in\nprevalence and complexity in a variety of domains, such as biology and finance.\nWhile deep learning methods are an effective tool for these problems, they\noften lack interpretability. In this work, we propose a novel modular prototype\nlearning framework for multivariable time series classification. In the first\nstage of our framework, encoders extract features from each variable\nindependently. Prototype layers identify single-variable prototypes in the\nresulting feature spaces. The next stage of our framework represents the\nmultivariable time series sample points in terms of their similarity to these\nsingle-variable prototypes. This results in an inherently interpretable\nrepresentation of multivariable patterns, on which prototype learning is\napplied to extract representative examples i.e. multivariable prototypes. Our\nframework is thus able to explicitly identify both informative patterns in the\nindividual variables, as well as the relationships between the variables. We\nvalidate our framework on a simulated dataset with embedded patterns, as well\nas a real human activity recognition problem. Our framework attains comparable\nor superior classification performance to existing time series classification\nmethods on these tasks. On the simulated dataset, we find that our model\nreturns interpretations consistent with the embedded patterns. Moreover, the\ninterpretations learned on the activity recognition dataset align with domain\nknowledge.'}","[{'name': 'Gaurav R. Ghosal'}, {'name': 'Reza Abbasi-Asl'}]",{'name': 'Reza Abbasi-Asl'},Reza Abbasi-Asl,"[{'href': 'http://arxiv.org/abs/2106.09636v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.09636v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]","14 pages, 6 figures",,
http://arxiv.org/abs/2106.09718v1,True,http://arxiv.org/abs/2106.09718v1,2021-06-17T17:59:59Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=17, tm_hour=17, tm_min=59, tm_sec=59, tm_wday=3, tm_yday=168, tm_isdst=0)",2021-06-17T17:59:59Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=17, tm_hour=17, tm_min=59, tm_sec=59, tm_wday=3, tm_yday=168, tm_isdst=0)","A Detection Threshold in the Amplitude Spectra Calculated from TESS
  Time-Series Data","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'A Detection Threshold in the Amplitude Spectra Calculated from TESS\n  Time-Series Data'}","We present results of time-series data simulation. We aimed at estimating the
threshold used for detecting signals in amplitude spectra, calculated from
simulating TESS photometry of up to one year duration. We selected the
threshold at a false alarm probability FAP=0.1% and derived S/N ratios between
4.6 and 5.7 depending on the data cadence and coverage. We also provide a
formula to estimate the threshold for any FAP adopted and a given number of
data points. Our result confirms that, to avoid spurious detection, space-based
photometry may require substantially higher S/N than that typically being
employed for ground-based data.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'We present results of time-series data simulation. We aimed at estimating the\nthreshold used for detecting signals in amplitude spectra, calculated from\nsimulating TESS photometry of up to one year duration. We selected the\nthreshold at a false alarm probability FAP=0.1% and derived S/N ratios between\n4.6 and 5.7 depending on the data cadence and coverage. We also provide a\nformula to estimate the threshold for any FAP adopted and a given number of\ndata points. Our result confirms that, to avoid spurious detection, space-based\nphotometry may require substantially higher S/N than that typically being\nemployed for ground-based data.'}","[{'name': 'A. S. Baran'}, {'name': 'C. Koen'}]",{'name': 'C. Koen'},C. Koen,"[{'href': 'http://arxiv.org/abs/2106.09718v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.09718v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'astro-ph.IM', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'astro-ph.IM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",accepted for publication in Acta Astronomica,,
http://arxiv.org/abs/2106.09851v1,True,http://arxiv.org/abs/2106.09851v1,2021-06-18T00:28:23Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=18, tm_hour=0, tm_min=28, tm_sec=23, tm_wday=4, tm_yday=169, tm_isdst=0)",2021-06-18T00:28:23Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=18, tm_hour=0, tm_min=28, tm_sec=23, tm_wday=4, tm_yday=169, tm_isdst=0)",Profile changes associated with DM events in PSR J1713+0747,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Profile changes associated with DM events in PSR J1713+0747'}","Propagation effects in the interstellar medium and intrinsic profile changes
can cause variability in the timing of pulsars, which limits the accuracy of
fundamental science done via pulsar timing. One of the best timing pulsars, PSR
J1713+0747, has gone through two ``dip'' events in its dispersion measure time
series. If these events reflect real changes in electron column density, they
should lead to multiple imaging. We show that the events are are well-fit by an
underdense corrugated sheet model, and look for associated variability in the
pulse profile using principal component analysis. We find that there are
transient pulse profile variations, but they vary in concert with the
dispersion measure, unlike what is expected from lensing due to a corrugated
sheet. The change is consistent in shape across profiles from both the
Greenbank and Arecibo radio observatories, and its amplitude appears to be
achromatic across the 820 MHz, 1.4 GHz, and 2.3 GHz bands, again unlike
expected from interference between lensed images. This result is puzzling. We
note that some of the predicted lensing effects would need higher time and
frequency resolution data than used in this analysis. Future events appear
likely, and storing baseband data or keeping multiple time-frequency
resolutions will allow more in-depth study of propagation effects and hence
improvements to pulsar timing accuracy.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': ""Propagation effects in the interstellar medium and intrinsic profile changes\ncan cause variability in the timing of pulsars, which limits the accuracy of\nfundamental science done via pulsar timing. One of the best timing pulsars, PSR\nJ1713+0747, has gone through two ``dip'' events in its dispersion measure time\nseries. If these events reflect real changes in electron column density, they\nshould lead to multiple imaging. We show that the events are are well-fit by an\nunderdense corrugated sheet model, and look for associated variability in the\npulse profile using principal component analysis. We find that there are\ntransient pulse profile variations, but they vary in concert with the\ndispersion measure, unlike what is expected from lensing due to a corrugated\nsheet. The change is consistent in shape across profiles from both the\nGreenbank and Arecibo radio observatories, and its amplitude appears to be\nachromatic across the 820 MHz, 1.4 GHz, and 2.3 GHz bands, again unlike\nexpected from interference between lensed images. This result is puzzling. We\nnote that some of the predicted lensing effects would need higher time and\nfrequency resolution data than used in this analysis. Future events appear\nlikely, and storing baseband data or keeping multiple time-frequency\nresolutions will allow more in-depth study of propagation effects and hence\nimprovements to pulsar timing accuracy.""}","[{'name': 'Fang Xi Lin'}, {'name': 'Hsiu-Hsien Lin'}, {'name': 'Jing Luo'}, {'name': 'Robert Main'}, {'name': 'James McKee'}, {'name': 'Ue-Li Pen'}, {'name': 'Dana Simard'}, {'name': 'Marten H. van Kerkwijk'}]",{'name': 'Marten H. van Kerkwijk'},Marten H. van Kerkwijk,"[{'href': 'http://arxiv.org/abs/2106.09851v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.09851v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'astro-ph.HE', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'astro-ph.HE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]","14 pages, 8 figures, submitted to MNRAS",,
http://arxiv.org/abs/2106.10038v1,True,http://arxiv.org/abs/2106.10038v1,2021-06-18T10:20:54Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=18, tm_hour=10, tm_min=20, tm_sec=54, tm_wday=4, tm_yday=169, tm_isdst=0)",2021-06-18T10:20:54Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=18, tm_hour=10, tm_min=20, tm_sec=54, tm_wday=4, tm_yday=169, tm_isdst=0)","Anomalous diffusion in the citation time series of scientific
  publications","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Anomalous diffusion in the citation time series of scientific\n  publications'}","We analyze the citation time-series of manuscripts in three different fields
of science; physics, social science and technology. The evolution of the
time-series of the yearly number of citations, namely the citation
trajectories, diffuse anomalously, their variance scales with time $\propto
t^{2H}$, where $H\neq 1/2$. We provide detailed analysis of the various factors
that lead to the anomalous behavior: non-stationarity, long-ranged correlations
and a fat-tailed increment distribution. The papers exhibit high degree of
heterogeneity, across the various fields, as the statistics of the highest
cited papers is fundamentally different from that of the lower ones. The
citation data is shown to be highly correlated and non-stationary; as all the
papers except the small percentage of them with high number of citations, die
out in time.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'We analyze the citation time-series of manuscripts in three different fields\nof science; physics, social science and technology. The evolution of the\ntime-series of the yearly number of citations, namely the citation\ntrajectories, diffuse anomalously, their variance scales with time $\\propto\nt^{2H}$, where $H\\neq 1/2$. We provide detailed analysis of the various factors\nthat lead to the anomalous behavior: non-stationarity, long-ranged correlations\nand a fat-tailed increment distribution. The papers exhibit high degree of\nheterogeneity, across the various fields, as the statistics of the highest\ncited papers is fundamentally different from that of the lower ones. The\ncitation data is shown to be highly correlated and non-stationary; as all the\npapers except the small percentage of them with high number of citations, die\nout in time.'}","[{'name': 'Maryam Zamani'}, {'name': 'Erez Aghion'}, {'name': 'Peter Pollner'}, {'name': 'Tamas Vicsek'}, {'name': 'Holger Kantz'}]",{'name': 'Holger Kantz'},Holger Kantz,"[{'href': 'http://arxiv.org/abs/2106.10038v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.10038v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.DL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.DL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]","12 pages, 12 figures",,
http://arxiv.org/abs/2106.10052v1,True,http://arxiv.org/abs/2106.10052v1,2021-06-18T11:00:24Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=18, tm_hour=11, tm_min=0, tm_sec=24, tm_wday=4, tm_yday=169, tm_isdst=0)",2021-06-18T11:00:24Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=18, tm_hour=11, tm_min=0, tm_sec=24, tm_wday=4, tm_yday=169, tm_isdst=0)",On Contrastive Representations of Stochastic Processes,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'On Contrastive Representations of Stochastic Processes'}","Learning representations of stochastic processes is an emerging problem in
machine learning with applications from meta-learning to physical object models
to time series. Typical methods rely on exact reconstruction of observations,
but this approach breaks down as observations become high-dimensional or noise
distributions become complex. To address this, we propose a unifying framework
for learning contrastive representations of stochastic processes (CRESP) that
does away with exact reconstruction. We dissect potential use cases for
stochastic process representations, and propose methods that accommodate each.
Empirically, we show that our methods are effective for learning
representations of periodic functions, 3D objects and dynamical processes. Our
methods tolerate noisy high-dimensional observations better than traditional
approaches, and the learned representations transfer to a range of downstream
tasks.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Learning representations of stochastic processes is an emerging problem in\nmachine learning with applications from meta-learning to physical object models\nto time series. Typical methods rely on exact reconstruction of observations,\nbut this approach breaks down as observations become high-dimensional or noise\ndistributions become complex. To address this, we propose a unifying framework\nfor learning contrastive representations of stochastic processes (CRESP) that\ndoes away with exact reconstruction. We dissect potential use cases for\nstochastic process representations, and propose methods that accommodate each.\nEmpirically, we show that our methods are effective for learning\nrepresentations of periodic functions, 3D objects and dynamical processes. Our\nmethods tolerate noisy high-dimensional observations better than traditional\napproaches, and the learned representations transfer to a range of downstream\ntasks.'}","[{'name': 'Emile Mathieu'}, {'name': 'Adam Foster'}, {'name': 'Yee Whye Teh'}]",{'name': 'Yee Whye Teh'},Yee Whye Teh,"[{'href': 'http://arxiv.org/abs/2106.10052v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.10052v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",,,
http://arxiv.org/abs/2106.10121v1,True,http://arxiv.org/abs/2106.10121v1,2021-06-18T13:22:12Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=18, tm_hour=13, tm_min=22, tm_sec=12, tm_wday=4, tm_yday=169, tm_isdst=0)",2021-06-18T13:22:12Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=18, tm_hour=13, tm_min=22, tm_sec=12, tm_wday=4, tm_yday=169, tm_isdst=0)","ScoreGrad: Multivariate Probabilistic Time Series Forecasting with
  Continuous Energy-based Generative Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'ScoreGrad: Multivariate Probabilistic Time Series Forecasting with\n  Continuous Energy-based Generative Models'}","Multivariate time series prediction has attracted a lot of attention because
of its wide applications such as intelligence transportation, AIOps. Generative
models have achieved impressive results in time series modeling because they
can model data distribution and take noise into consideration. However, many
existing works can not be widely used because of the constraints of functional
form of generative models or the sensitivity to hyperparameters. In this paper,
we propose ScoreGrad, a multivariate probabilistic time series forecasting
framework based on continuous energy-based generative models. ScoreGrad is
composed of time series feature extraction module and conditional stochastic
differential equation based score matching module. The prediction can be
achieved by iteratively solving reverse-time SDE. To the best of our knowledge,
ScoreGrad is the first continuous energy based generative model used for time
series forecasting. Furthermore, ScoreGrad achieves state-of-the-art results on
six real-world datasets. The impact of hyperparameters and sampler types on the
performance are also explored. Code is available at
https://github.com/yantijin/ScoreGradPred.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Multivariate time series prediction has attracted a lot of attention because\nof its wide applications such as intelligence transportation, AIOps. Generative\nmodels have achieved impressive results in time series modeling because they\ncan model data distribution and take noise into consideration. However, many\nexisting works can not be widely used because of the constraints of functional\nform of generative models or the sensitivity to hyperparameters. In this paper,\nwe propose ScoreGrad, a multivariate probabilistic time series forecasting\nframework based on continuous energy-based generative models. ScoreGrad is\ncomposed of time series feature extraction module and conditional stochastic\ndifferential equation based score matching module. The prediction can be\nachieved by iteratively solving reverse-time SDE. To the best of our knowledge,\nScoreGrad is the first continuous energy based generative model used for time\nseries forecasting. Furthermore, ScoreGrad achieves state-of-the-art results on\nsix real-world datasets. The impact of hyperparameters and sampler types on the\nperformance are also explored. Code is available at\nhttps://github.com/yantijin/ScoreGradPred.'}","[{'name': 'Tijin Yan'}, {'name': 'Hongwei Zhang'}, {'name': 'Tong Zhou'}, {'name': 'Yufeng Zhan'}, {'name': 'Yuanqing Xia'}]",{'name': 'Yuanqing Xia'},Yuanqing Xia,"[{'href': 'http://arxiv.org/abs/2106.10121v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.10121v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]","12 pages, 10 figures",,
http://arxiv.org/abs/2106.10157v1,True,http://arxiv.org/abs/2106.10157v1,2021-06-18T14:50:11Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=18, tm_hour=14, tm_min=50, tm_sec=11, tm_wday=4, tm_yday=169, tm_isdst=0)",2021-06-18T14:50:11Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=18, tm_hour=14, tm_min=50, tm_sec=11, tm_wday=4, tm_yday=169, tm_isdst=0)",pyWATTS: Python Workflow Automation Tool for Time Series,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'pyWATTS: Python Workflow Automation Tool for Time Series'}","Time series data are fundamental for a variety of applications, ranging from
financial markets to energy systems. Due to their importance, the number and
complexity of tools and methods used for time series analysis is constantly
increasing. However, due to unclear APIs and a lack of documentation,
researchers struggle to integrate them into their research projects and
replicate results. Additionally, in time series analysis there exist many
repetitive tasks, which are often re-implemented for each project,
unnecessarily costing time. To solve these problems we present
\texttt{pyWATTS}, an open-source Python-based package that is a non-sequential
workflow automation tool for the analysis of time series data. pyWATTS includes
modules with clearly defined interfaces to enable seamless integration of new
or existing methods, subpipelining to easily reproduce repetitive tasks, load
and save functionality to simply replicate results, and native support for key
Python machine learning libraries such as scikit-learn, PyTorch, and Keras.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Time series data are fundamental for a variety of applications, ranging from\nfinancial markets to energy systems. Due to their importance, the number and\ncomplexity of tools and methods used for time series analysis is constantly\nincreasing. However, due to unclear APIs and a lack of documentation,\nresearchers struggle to integrate them into their research projects and\nreplicate results. Additionally, in time series analysis there exist many\nrepetitive tasks, which are often re-implemented for each project,\nunnecessarily costing time. To solve these problems we present\n\\texttt{pyWATTS}, an open-source Python-based package that is a non-sequential\nworkflow automation tool for the analysis of time series data. pyWATTS includes\nmodules with clearly defined interfaces to enable seamless integration of new\nor existing methods, subpipelining to easily reproduce repetitive tasks, load\nand save functionality to simply replicate results, and native support for key\nPython machine learning libraries such as scikit-learn, PyTorch, and Keras.'}","[{'name': 'Benedikt Heidrich'}, {'name': 'Andreas Bartschat'}, {'name': 'Marian Turowski'}, {'name': 'Oliver Neumann'}, {'name': 'Kaleb Phipps'}, {'name': 'Stefan Meisenbacher'}, {'name': 'Kai Schmieder'}, {'name': 'Nicole Ludwig'}, {'name': 'Ralf Mikut'}, {'name': 'Veit Hagenmeyer'}]",{'name': 'Veit Hagenmeyer'},Veit Hagenmeyer,"[{'href': 'http://arxiv.org/abs/2106.10157v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.10157v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",,,
http://arxiv.org/abs/2106.10159v1,True,http://arxiv.org/abs/2106.10159v1,2021-06-18T14:51:14Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=18, tm_hour=14, tm_min=51, tm_sec=14, tm_wday=4, tm_yday=169, tm_isdst=0)",2021-06-18T14:51:14Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=18, tm_hour=14, tm_min=51, tm_sec=14, tm_wday=4, tm_yday=169, tm_isdst=0)","FinGAT: Financial Graph Attention Networks for Recommending Top-K
  Profitable Stocks","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'FinGAT: Financial Graph Attention Networks for Recommending Top-K\n  Profitable Stocks'}","Financial technology (FinTech) has drawn much attention among investors and
companies. While conventional stock analysis in FinTech targets at predicting
stock prices, less effort is made for profitable stock recommendation. Besides,
in existing approaches on modeling time series of stock prices, the
relationships among stocks and sectors (i.e., categories of stocks) are either
neglected or pre-defined. Ignoring stock relationships will miss the
information shared between stocks while using pre-defined relationships cannot
depict the latent interactions or influence of stock prices between stocks. In
this work, we aim at recommending the top-K profitable stocks in terms of
return ratio using time series of stock prices and sector information. We
propose a novel deep learning-based model, Financial Graph Attention Networks
(FinGAT), to tackle the task under the setting that no pre-defined
relationships between stocks are given. The idea of FinGAT is three-fold.
First, we devise a hierarchical learning component to learn short-term and
long-term sequential patterns from stock time series. Second, a fully-connected
graph between stocks and a fully-connected graph between sectors are
constructed, along with graph attention networks, to learn the latent
interactions among stocks and sectors. Third, a multi-task objective is devised
to jointly recommend the profitable stocks and predict the stock movement.
Experiments conducted on Taiwan Stock, S&P 500, and NASDAQ datasets exhibit
remarkable recommendation performance of our FinGAT, comparing to
state-of-the-art methods.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Financial technology (FinTech) has drawn much attention among investors and\ncompanies. While conventional stock analysis in FinTech targets at predicting\nstock prices, less effort is made for profitable stock recommendation. Besides,\nin existing approaches on modeling time series of stock prices, the\nrelationships among stocks and sectors (i.e., categories of stocks) are either\nneglected or pre-defined. Ignoring stock relationships will miss the\ninformation shared between stocks while using pre-defined relationships cannot\ndepict the latent interactions or influence of stock prices between stocks. In\nthis work, we aim at recommending the top-K profitable stocks in terms of\nreturn ratio using time series of stock prices and sector information. We\npropose a novel deep learning-based model, Financial Graph Attention Networks\n(FinGAT), to tackle the task under the setting that no pre-defined\nrelationships between stocks are given. The idea of FinGAT is three-fold.\nFirst, we devise a hierarchical learning component to learn short-term and\nlong-term sequential patterns from stock time series. Second, a fully-connected\ngraph between stocks and a fully-connected graph between sectors are\nconstructed, along with graph attention networks, to learn the latent\ninteractions among stocks and sectors. Third, a multi-task objective is devised\nto jointly recommend the profitable stocks and predict the stock movement.\nExperiments conducted on Taiwan Stock, S&P 500, and NASDAQ datasets exhibit\nremarkable recommendation performance of our FinGAT, comparing to\nstate-of-the-art methods.'}","[{'name': 'Yi-Ling Hsu'}, {'name': 'Yu-Che Tsai'}, {'name': 'Cheng-Te Li'}]",{'name': 'Cheng-Te Li'},Cheng-Te Li,"[{'href': 'http://arxiv.org/abs/2106.10159v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.10159v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]","Accepted to IEEE TKDE 2021. The first two authors equally contribute
  to this work. Code is available at
  https://github.com/Roytsai27/Financial-GraphAttention",,
http://arxiv.org/abs/2106.10203v1,True,http://arxiv.org/abs/2106.10203v1,2021-06-18T16:13:59Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=18, tm_hour=16, tm_min=13, tm_sec=59, tm_wday=4, tm_yday=169, tm_isdst=0)",2021-06-18T16:13:59Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=18, tm_hour=16, tm_min=13, tm_sec=59, tm_wday=4, tm_yday=169, tm_isdst=0)","Trend estimation and short-term forecasting of COVID-19 cases and deaths
  worldwide","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Trend estimation and short-term forecasting of COVID-19 cases and deaths\n  worldwide'}","Since the beginning of the COVID-19 pandemic, many dashboards have emerged as
useful tools to monitor the evolution of the pandemic, inform the public, and
assist governments in decision making. Our goal is to develop a globally
applicable method, integrated in a twice daily updated dashboard that provides
an estimate of the trend in the evolution of the number of cases and deaths
from reported data of more than 200 countries and territories, as well as a
seven-day forecast. One of the significant difficulties to manage a quickly
propagating epidemic is that the details of the dynamic needed to forecast its
evolution are obscured by the delays in the identification of cases and deaths
and by irregular reporting. Our forecasting methodology substantially relies on
estimating the underlying trend in the observed time series using robust
seasonal trend decomposition techniques. This allows us to obtain forecasts
with simple, yet effective extrapolation methods in linear or log scale. We
present the results of an assessment of our forecasting methodology and discuss
its application to the production of global and regional risk maps.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Since the beginning of the COVID-19 pandemic, many dashboards have emerged as\nuseful tools to monitor the evolution of the pandemic, inform the public, and\nassist governments in decision making. Our goal is to develop a globally\napplicable method, integrated in a twice daily updated dashboard that provides\nan estimate of the trend in the evolution of the number of cases and deaths\nfrom reported data of more than 200 countries and territories, as well as a\nseven-day forecast. One of the significant difficulties to manage a quickly\npropagating epidemic is that the details of the dynamic needed to forecast its\nevolution are obscured by the delays in the identification of cases and deaths\nand by irregular reporting. Our forecasting methodology substantially relies on\nestimating the underlying trend in the observed time series using robust\nseasonal trend decomposition techniques. This allows us to obtain forecasts\nwith simple, yet effective extrapolation methods in linear or log scale. We\npresent the results of an assessment of our forecasting methodology and discuss\nits application to the production of global and regional risk maps.'}","[{'name': 'Ekaterina Krymova'}, {'name': 'Benjam√≠n B√©jar'}, {'name': 'Dorina Thanou'}, {'name': 'Tao Sun'}, {'name': 'Elisa Manetti'}, {'name': 'Gavin Lee'}, {'name': 'Kristen Namigai'}, {'name': 'Christine Choirat'}, {'name': 'Antoine Flahault'}, {'name': 'Guillaume Obozinski'}]",{'name': 'Guillaume Obozinski'},Guillaume Obozinski,"[{'href': 'http://arxiv.org/abs/2106.10203v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.10203v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'stat.AP', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'stat.AP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '92D30, 00-01, 60G25', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",15 pages including 5 pages of supplementary material,,
http://arxiv.org/abs/2106.10210v1,True,http://arxiv.org/abs/2106.10210v1,2021-06-18T16:30:09Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=18, tm_hour=16, tm_min=30, tm_sec=9, tm_wday=4, tm_yday=169, tm_isdst=0)",2021-06-18T16:30:09Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=18, tm_hour=16, tm_min=30, tm_sec=9, tm_wday=4, tm_yday=169, tm_isdst=0)","Combining Pseudo-Point and State Space Approximations for Sum-Separable
  Gaussian Processes","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Combining Pseudo-Point and State Space Approximations for Sum-Separable\n  Gaussian Processes'}","Gaussian processes (GPs) are important probabilistic tools for inference and
learning in spatio-temporal modelling problems such as those in climate science
and epidemiology. However, existing GP approximations do not simultaneously
support large numbers of off-the-grid spatial data-points and long time-series
which is a hallmark of many applications.
  Pseudo-point approximations, one of the gold-standard methods for scaling GPs
to large data sets, are well suited for handling off-the-grid spatial data.
However, they cannot handle long temporal observation horizons effectively
reverting to cubic computational scaling in the time dimension. State space GP
approximations are well suited to handling temporal data, if the temporal GP
prior admits a Markov form, leading to linear complexity in the number of
temporal observations, but have a cubic spatial cost and cannot handle
off-the-grid spatial data.
  In this work we show that there is a simple and elegant way to combine
pseudo-point methods with the state space GP approximation framework to get the
best of both worlds. The approach hinges on a surprising conditional
independence property which applies to space--time separable GPs. We
demonstrate empirically that the combined approach is more scalable and
applicable to a greater range of spatio-temporal problems than either method on
its own.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Gaussian processes (GPs) are important probabilistic tools for inference and\nlearning in spatio-temporal modelling problems such as those in climate science\nand epidemiology. However, existing GP approximations do not simultaneously\nsupport large numbers of off-the-grid spatial data-points and long time-series\nwhich is a hallmark of many applications.\n  Pseudo-point approximations, one of the gold-standard methods for scaling GPs\nto large data sets, are well suited for handling off-the-grid spatial data.\nHowever, they cannot handle long temporal observation horizons effectively\nreverting to cubic computational scaling in the time dimension. State space GP\napproximations are well suited to handling temporal data, if the temporal GP\nprior admits a Markov form, leading to linear complexity in the number of\ntemporal observations, but have a cubic spatial cost and cannot handle\noff-the-grid spatial data.\n  In this work we show that there is a simple and elegant way to combine\npseudo-point methods with the state space GP approximation framework to get the\nbest of both worlds. The approach hinges on a surprising conditional\nindependence property which applies to space--time separable GPs. We\ndemonstrate empirically that the combined approach is more scalable and\napplicable to a greater range of spatio-temporal problems than either method on\nits own.'}","[{'name': 'Will Tebbutt'}, {'name': 'Arno Solin'}, {'name': 'Richard E. Turner'}]",{'name': 'Richard E. Turner'},Richard E. Turner,"[{'href': 'http://arxiv.org/abs/2106.10210v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.10210v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",,,
http://arxiv.org/abs/2106.10370v1,True,http://arxiv.org/abs/2106.10370v1,2021-06-18T22:10:43Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=18, tm_hour=22, tm_min=10, tm_sec=43, tm_wday=4, tm_yday=169, tm_isdst=0)",2021-06-18T22:10:43Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=18, tm_hour=22, tm_min=10, tm_sec=43, tm_wday=4, tm_yday=169, tm_isdst=0)","On the benefits of maximum likelihood estimation for Regression and
  Forecasting","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'On the benefits of maximum likelihood estimation for Regression and\n  Forecasting'}","We advocate for a practical Maximum Likelihood Estimation (MLE) approach for
regression and forecasting, as an alternative to the typical approach of
Empirical Risk Minimization (ERM) for a specific target metric. This approach
is better suited to capture inductive biases such as prior domain knowledge in
datasets, and can output post-hoc estimators at inference time that can
optimize different types of target metrics. We present theoretical results to
demonstrate that our approach is always competitive with any estimator for the
target metric under some general conditions, and in many practical settings
(such as Poisson Regression) can actually be much superior to ERM. We
demonstrate empirically that our method instantiated with a well-designed
general purpose mixture likelihood family can obtain superior performance over
ERM for a variety of tasks across time-series forecasting and regression
datasets with different data distributions.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'We advocate for a practical Maximum Likelihood Estimation (MLE) approach for\nregression and forecasting, as an alternative to the typical approach of\nEmpirical Risk Minimization (ERM) for a specific target metric. This approach\nis better suited to capture inductive biases such as prior domain knowledge in\ndatasets, and can output post-hoc estimators at inference time that can\noptimize different types of target metrics. We present theoretical results to\ndemonstrate that our approach is always competitive with any estimator for the\ntarget metric under some general conditions, and in many practical settings\n(such as Poisson Regression) can actually be much superior to ERM. We\ndemonstrate empirically that our method instantiated with a well-designed\ngeneral purpose mixture likelihood family can obtain superior performance over\nERM for a variety of tasks across time-series forecasting and regression\ndatasets with different data distributions.'}","[{'name': 'Pranjal Awasthi'}, {'name': 'Abhimanyu Das'}, {'name': 'Rajat Sen'}, {'name': 'Ananda Theertha Suresh'}]",{'name': 'Ananda Theertha Suresh'},Ananda Theertha Suresh,"[{'href': 'http://arxiv.org/abs/2106.10370v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.10370v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",,,
http://arxiv.org/abs/2106.10277v1,True,http://arxiv.org/abs/2106.10277v1,2021-06-19T04:37:39Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=19, tm_hour=4, tm_min=37, tm_sec=39, tm_wday=5, tm_yday=170, tm_isdst=0)",2021-06-19T04:37:39Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=19, tm_hour=4, tm_min=37, tm_sec=39, tm_wday=5, tm_yday=170, tm_isdst=0)",GPLA-12: An Acoustic Signal Dataset of Gas Pipeline Leakage,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'GPLA-12: An Acoustic Signal Dataset of Gas Pipeline Leakage'}","In this paper, we introduce a new acoustic leakage dataset of gas pipelines,
called as GPLA-12, which has 12 categories over 684 training/testing acoustic
signals. Unlike massive image and voice datasets, there have relatively few
acoustic signal datasets, especially for engineering fault detection. In order
to enhance the development of fault diagnosis, we collect acoustic leakage
signals on the basis of an intact gas pipe system with external artificial
leakages, and then preprocess the collected data with structured tailoring
which are turned into GPLA-12. GPLA-12 dedicates to serve as a feature learning
dataset for time-series tasks and classifications. To further understand the
dataset, we train both shadow and deep learning algorithms to observe the
performance. The dataset as well as the pretrained models have been released at
both www.daip.club and github.com/Deep-AI-Application-DAIP","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'In this paper, we introduce a new acoustic leakage dataset of gas pipelines,\ncalled as GPLA-12, which has 12 categories over 684 training/testing acoustic\nsignals. Unlike massive image and voice datasets, there have relatively few\nacoustic signal datasets, especially for engineering fault detection. In order\nto enhance the development of fault diagnosis, we collect acoustic leakage\nsignals on the basis of an intact gas pipe system with external artificial\nleakages, and then preprocess the collected data with structured tailoring\nwhich are turned into GPLA-12. GPLA-12 dedicates to serve as a feature learning\ndataset for time-series tasks and classifications. To further understand the\ndataset, we train both shadow and deep learning algorithms to observe the\nperformance. The dataset as well as the pretrained models have been released at\nboth www.daip.club and github.com/Deep-AI-Application-DAIP'}","[{'name': 'Jie Li'}, {'name': 'Lizhong Yao'}]",{'name': 'Lizhong Yao'},Lizhong Yao,"[{'href': 'http://arxiv.org/abs/2106.10277v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.10277v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'eess.AS', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'eess.AS', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SD', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",,,
http://arxiv.org/abs/2106.10466v1,True,http://arxiv.org/abs/2106.10466v1,2021-06-19T10:24:13Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=19, tm_hour=10, tm_min=24, tm_sec=13, tm_wday=5, tm_yday=170, tm_isdst=0)",2021-06-19T10:24:13Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=19, tm_hour=10, tm_min=24, tm_sec=13, tm_wday=5, tm_yday=170, tm_isdst=0)","Learning Timestamp-Level Representations for Time Series with
  Hierarchical Contrastive Loss","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Learning Timestamp-Level Representations for Time Series with\n  Hierarchical Contrastive Loss'}","This paper presents TS2Vec, a universal framework for learning
timestamp-level representations of time series. Unlike existing methods, TS2Vec
performs timestamp-wise discrimination, which learns a contextual
representation vector directly for each timestamp. We find that the learned
representations have superior predictive ability. A linear regression trained
on top of the learned representations outperforms previous SOTAs for supervised
time series forecasting. Also, the instance-level representations can be simply
obtained by applying a max pooling layer on top of learned representations of
all timestamps. We conduct extensive experiments on time series classification
tasks to evaluate the quality of instance-level representations. As a result,
TS2Vec achieves significant improvement compared with existing SOTAs of
unsupervised time series representation on 125 UCR datasets and 29 UEA
datasets. The source code is publicly available at
https://github.com/yuezhihan/ts2vec.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'This paper presents TS2Vec, a universal framework for learning\ntimestamp-level representations of time series. Unlike existing methods, TS2Vec\nperforms timestamp-wise discrimination, which learns a contextual\nrepresentation vector directly for each timestamp. We find that the learned\nrepresentations have superior predictive ability. A linear regression trained\non top of the learned representations outperforms previous SOTAs for supervised\ntime series forecasting. Also, the instance-level representations can be simply\nobtained by applying a max pooling layer on top of learned representations of\nall timestamps. We conduct extensive experiments on time series classification\ntasks to evaluate the quality of instance-level representations. As a result,\nTS2Vec achieves significant improvement compared with existing SOTAs of\nunsupervised time series representation on 125 UCR datasets and 29 UEA\ndatasets. The source code is publicly available at\nhttps://github.com/yuezhihan/ts2vec.'}","[{'name': 'Zhihan Yue'}, {'name': 'Yujing Wang'}, {'name': 'Juanyong Duan'}, {'name': 'Tianmeng Yang'}, {'name': 'Congrui Huang'}, {'name': 'Bixiong Xu'}]",{'name': 'Bixiong Xu'},Bixiong Xu,"[{'href': 'http://arxiv.org/abs/2106.10466v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.10466v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]","20 pages, 6 figures",,
http://arxiv.org/abs/2106.10477v1,True,http://arxiv.org/abs/2106.10477v1,2021-06-19T11:50:39Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=19, tm_hour=11, tm_min=50, tm_sec=39, tm_wday=5, tm_yday=170, tm_isdst=0)",2021-06-19T11:50:39Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=19, tm_hour=11, tm_min=50, tm_sec=39, tm_wday=5, tm_yday=170, tm_isdst=0)",Generalized Spatial and Spatiotemporal ARCH Models,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Generalized Spatial and Spatiotemporal ARCH Models'}","In time-series analyses, particularly for finance, generalized autoregressive
conditional heteroscedasticity (GARCH) models are widely applied statistical
tools for modelling volatility clusters (i.e., periods of increased or
decreased risk). In contrast, it has not been considered to be of critical
importance until now to model spatial dependence in the conditional second
moments. Only a few models have been proposed for modelling local clusters of
increased risks. In this paper, we introduce a novel spatial GARCH process in a
unified spatial and spatiotemporal GARCH framework, which also covers all
previously proposed spatial ARCH models, exponential spatial GARCH, and
time-series GARCH models. In contrast to previous spatiotemporal and time
series models, this spatial GARCH allows for instantaneous spill-overs across
all spatial units. For this common modelling framework, estimators are derived
based on a non-linear least-squares approach. Eventually, the use of the model
is demonstrated by a Monte Carlo simulation study and by an empirical example
that focuses on real estate prices from 1995 to 2014 across the ZIP-Code areas
of Berlin. A spatial autoregressive model is applied to the data to illustrate
how locally varying model uncertainties (e.g., due to latent regressors) can be
captured by the spatial GARCH-type models.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'In time-series analyses, particularly for finance, generalized autoregressive\nconditional heteroscedasticity (GARCH) models are widely applied statistical\ntools for modelling volatility clusters (i.e., periods of increased or\ndecreased risk). In contrast, it has not been considered to be of critical\nimportance until now to model spatial dependence in the conditional second\nmoments. Only a few models have been proposed for modelling local clusters of\nincreased risks. In this paper, we introduce a novel spatial GARCH process in a\nunified spatial and spatiotemporal GARCH framework, which also covers all\npreviously proposed spatial ARCH models, exponential spatial GARCH, and\ntime-series GARCH models. In contrast to previous spatiotemporal and time\nseries models, this spatial GARCH allows for instantaneous spill-overs across\nall spatial units. For this common modelling framework, estimators are derived\nbased on a non-linear least-squares approach. Eventually, the use of the model\nis demonstrated by a Monte Carlo simulation study and by an empirical example\nthat focuses on real estate prices from 1995 to 2014 across the ZIP-Code areas\nof Berlin. A spatial autoregressive model is applied to the data to illustrate\nhow locally varying model uncertainties (e.g., due to latent regressors) can be\ncaptured by the spatial GARCH-type models.'}","[{'name': 'Philipp Otto'}, {'name': 'Wolfgang Schmid'}]",{'name': 'Wolfgang Schmid'},Wolfgang Schmid,"[{'href': 'http://arxiv.org/abs/2106.10477v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.10477v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'stat.ME', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'stat.ME', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'econ.EM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",,,
http://arxiv.org/abs/2106.10627v1,True,http://arxiv.org/abs/2106.10627v1,2021-06-20T05:17:05Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=20, tm_hour=5, tm_min=17, tm_sec=5, tm_wday=6, tm_yday=171, tm_isdst=0)",2021-06-20T05:17:05Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=20, tm_hour=5, tm_min=17, tm_sec=5, tm_wday=6, tm_yday=171, tm_isdst=0)",Experimentally testable whole brain manifolds that recapitulate behavior,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Experimentally testable whole brain manifolds that recapitulate behavior'}","We propose an algorithm grounded in dynamical systems theory that generalizes
manifold learning from a global state representation, to a network of local
interacting manifolds termed a Generative Manifold Network (GMN). Manifolds are
discovered using the convergent cross mapping (CCM) causal inference algorithm
which are then compressed into a reduced redundancy network. The representation
is a network of manifolds embedded from observational data where each
orthogonal axis of a local manifold is an embedding of a individually
identifiable neuron or brain area that has exact correspondence in the real
world. As such these can be experimentally manipulated to test hypotheses
derived from theory and data analysis. Here we demonstrate that this
representation preserves the essential features of the brain of flies,larval
zebrafish and humans. In addition to accurate near-term prediction, the GMN
model can be used to synthesize realistic time series of whole brain neuronal
activity and locomotion viewed over the long term. Thus, as a final validation
of how well GMN captures essential dynamic information, we show that the
artificially generated time series can be used as a training set to predict
out-of-sample observed fly locomotion, as well as brain activity in out of
sample withheld data not used in model building. Remarkably, the artificially
generated time series show realistic novel behaviors that do not exist in the
training data, but that do exist in the out-of-sample observational data. This
suggests that GMN captures inherently emergent properties of the network. We
suggest our approach may be a generic recipe for mapping time series
observations of any complex nonlinear network into a model that is able to
generate naturalistic system behaviors that identifies variables that have real
world correspondence and can be experimentally manipulated.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'We propose an algorithm grounded in dynamical systems theory that generalizes\nmanifold learning from a global state representation, to a network of local\ninteracting manifolds termed a Generative Manifold Network (GMN). Manifolds are\ndiscovered using the convergent cross mapping (CCM) causal inference algorithm\nwhich are then compressed into a reduced redundancy network. The representation\nis a network of manifolds embedded from observational data where each\northogonal axis of a local manifold is an embedding of a individually\nidentifiable neuron or brain area that has exact correspondence in the real\nworld. As such these can be experimentally manipulated to test hypotheses\nderived from theory and data analysis. Here we demonstrate that this\nrepresentation preserves the essential features of the brain of flies,larval\nzebrafish and humans. In addition to accurate near-term prediction, the GMN\nmodel can be used to synthesize realistic time series of whole brain neuronal\nactivity and locomotion viewed over the long term. Thus, as a final validation\nof how well GMN captures essential dynamic information, we show that the\nartificially generated time series can be used as a training set to predict\nout-of-sample observed fly locomotion, as well as brain activity in out of\nsample withheld data not used in model building. Remarkably, the artificially\ngenerated time series show realistic novel behaviors that do not exist in the\ntraining data, but that do exist in the out-of-sample observational data. This\nsuggests that GMN captures inherently emergent properties of the network. We\nsuggest our approach may be a generic recipe for mapping time series\nobservations of any complex nonlinear network into a model that is able to\ngenerate naturalistic system behaviors that identifies variables that have real\nworld correspondence and can be experimentally manipulated.'}","[{'name': 'Gerald M Pao'}, {'name': 'Cameron Smith'}, {'name': 'Joseph Park'}, {'name': 'Keichi Takahashi'}, {'name': 'Wassapon Watanakeesuntorn'}, {'name': 'Hiroaki Natsukawa'}, {'name': 'Sreekanth H Chalasani'}, {'name': 'Tom Lorimer'}, {'name': 'Ryousei Takano'}, {'name': 'Nuttida Rungratsameetaweemana'}, {'name': 'George Sugihara'}]",{'name': 'George Sugihara'},George Sugihara,"[{'href': 'http://arxiv.org/abs/2106.10627v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.10627v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'q-bio.NC', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'q-bio.NC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.DS', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]","20 pages, 15 figures; corresponding author: Gerald Pao
  geraldpao@gmail.com",,
http://arxiv.org/abs/2106.10631v1,True,http://arxiv.org/abs/2106.10631v1,2021-06-20T05:53:12Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=20, tm_hour=5, tm_min=53, tm_sec=12, tm_wday=6, tm_yday=171, tm_isdst=0)",2021-06-20T05:53:12Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=20, tm_hour=5, tm_min=53, tm_sec=12, tm_wday=6, tm_yday=171, tm_isdst=0)",A mathematical perspective on edge-centric functional connectivity,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'A mathematical perspective on edge-centric functional connectivity'}","Edge-centric functional connectivity (eFC) has recently been proposed to
characterise the finest time resolution on the FC dynamics without the
concomitant assumptions of sliding-window approaches. Here, we lay the
mathematical foundations for the edge-centric analysis and examine its main
findings from a quantitative perspective. The proposed framework provides a
theoretical explanation for the observed occurrence of high-amplitude edge
cofluctuations across datasets and clarifies why a few large events drive the
node-centric FC (nFC). Our exposition also constitutes a critique of the
edge-centric approach as currently applied to functional MRI (fMRI) time
series. The central argument is that the existing findings based on edge time
series can be derived from the static nFC under a null hypothesis that only
accounts for the observed static spatial correlations and not the temporal
ones. Challenging our analytic predictions against fMRI data from the Human
Connectome Project confirms that the nFC is sufficient to replicate the eFC
matrix, the edge communities, the large cofluctuations, and the corresponding
brain activity mode. We conclude that the temporal structure of the edge time
series has not so far been exploited sufficiently and encourage further work to
explore features that cannot be explained by the presented static null model.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Edge-centric functional connectivity (eFC) has recently been proposed to\ncharacterise the finest time resolution on the FC dynamics without the\nconcomitant assumptions of sliding-window approaches. Here, we lay the\nmathematical foundations for the edge-centric analysis and examine its main\nfindings from a quantitative perspective. The proposed framework provides a\ntheoretical explanation for the observed occurrence of high-amplitude edge\ncofluctuations across datasets and clarifies why a few large events drive the\nnode-centric FC (nFC). Our exposition also constitutes a critique of the\nedge-centric approach as currently applied to functional MRI (fMRI) time\nseries. The central argument is that the existing findings based on edge time\nseries can be derived from the static nFC under a null hypothesis that only\naccounts for the observed static spatial correlations and not the temporal\nones. Challenging our analytic predictions against fMRI data from the Human\nConnectome Project confirms that the nFC is sufficient to replicate the eFC\nmatrix, the edge communities, the large cofluctuations, and the corresponding\nbrain activity mode. We conclude that the temporal structure of the edge time\nseries has not so far been exploited sufficiently and encourage further work to\nexplore features that cannot be explained by the presented static null model.'}","[{'name': 'Leonardo Novelli'}, {'name': 'Adeel Razi'}]",{'name': 'Adeel Razi'},Adeel Razi,"[{'href': 'http://arxiv.org/abs/2106.10631v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.10631v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'q-bio.NC', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'q-bio.NC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.data-an', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",,,
http://arxiv.org/abs/2106.10754v1,True,http://arxiv.org/abs/2106.10754v1,2021-06-20T21:31:42Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=20, tm_hour=21, tm_min=31, tm_sec=42, tm_wday=6, tm_yday=171, tm_isdst=0)",2021-06-20T21:31:42Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=20, tm_hour=21, tm_min=31, tm_sec=42, tm_wday=6, tm_yday=171, tm_isdst=0)","A SOPHIE RV search for giant planets around young nearby stars (YNS). A
  combination with the HARPS YNS survey","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'A SOPHIE RV search for giant planets around young nearby stars (YNS). A\n  combination with the HARPS YNS survey'}","The search of close (a<=5 au) giant planet(GP) companions with radial
velocity(RV) around young stars and the estimate of their occurrence rates is
important to constrain the migration timescales. Furthermore, this search will
allow the giant planet occurrence rates to be computed at all separations via
the combination with direct imaging techniques. The RV search around young
stars is a challenge as they are generally faster rotators than older stars of
similar spectral types and they exhibit signatures of spots or pulsation in
their RV time series. Specific analyses are necessary to characterize, and
possibly correct for, this activity. Our aim is to search for planets around
young nearby stars and to estimate the GP occurrence rates for periods up to
1000 days. We used the SOPHIE spectrograph to observe 63 A-M young (<400 Myr)
stars. We used our SAFIR software to compute the RVs and other spectroscopic
observables. We then combined this survey with the HARPS YNS survey to compute
the companion occurrence rates on a total of 120 young A-M stars. We report one
new trend compatible with a planetary companion on HD109647. We also report
HD105693 and HD112097 as binaries, and we confirm the binarity of HD2454,
HD13531, HD17250A, HD28945, HD39587, HD131156, HD 142229, HD186704A, and HD
195943. We constrained for the first time the orbital parameters of HD195943B.
We refute the HD13507 single brown dwarf (BD) companion solution and propose a
double BD companion solution. Based on our sample of 120 young stars, we obtain
a GP occurrence rate of 1_{-0.3}^{+2.2}% for periods lower than 1000 days, and
we obtain an upper limit on BD occurrence rateof 0.9_{-0.9}^{+2}% in the same
period range. We report a possible lack of close (1<P<1000 days) GPs around
young FK stars compared to their older counterparts, with a confidence level of
90%.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'The search of close (a<=5 au) giant planet(GP) companions with radial\nvelocity(RV) around young stars and the estimate of their occurrence rates is\nimportant to constrain the migration timescales. Furthermore, this search will\nallow the giant planet occurrence rates to be computed at all separations via\nthe combination with direct imaging techniques. The RV search around young\nstars is a challenge as they are generally faster rotators than older stars of\nsimilar spectral types and they exhibit signatures of spots or pulsation in\ntheir RV time series. Specific analyses are necessary to characterize, and\npossibly correct for, this activity. Our aim is to search for planets around\nyoung nearby stars and to estimate the GP occurrence rates for periods up to\n1000 days. We used the SOPHIE spectrograph to observe 63 A-M young (<400 Myr)\nstars. We used our SAFIR software to compute the RVs and other spectroscopic\nobservables. We then combined this survey with the HARPS YNS survey to compute\nthe companion occurrence rates on a total of 120 young A-M stars. We report one\nnew trend compatible with a planetary companion on HD109647. We also report\nHD105693 and HD112097 as binaries, and we confirm the binarity of HD2454,\nHD13531, HD17250A, HD28945, HD39587, HD131156, HD 142229, HD186704A, and HD\n195943. We constrained for the first time the orbital parameters of HD195943B.\nWe refute the HD13507 single brown dwarf (BD) companion solution and propose a\ndouble BD companion solution. Based on our sample of 120 young stars, we obtain\na GP occurrence rate of 1_{-0.3}^{+2.2}% for periods lower than 1000 days, and\nwe obtain an upper limit on BD occurrence rateof 0.9_{-0.9}^{+2}% in the same\nperiod range. We report a possible lack of close (1<P<1000 days) GPs around\nyoung FK stars compared to their older counterparts, with a confidence level of\n90%.'}","[{'name': 'A. Grandjean'}, {'name': 'A. -M. Lagrange'}, {'name': 'N. Meunier'}, {'name': 'P. Rubini'}, {'name': 'S. Desidera'}, {'name': 'F. Galland'}, {'name': 'S. Borgniet'}, {'name': 'N. Zicher'}, {'name': 'S. Messina'}, {'name': 'G. Chauvin'}, {'name': 'M. Sterzik'}, {'name': 'B. Pantoja'}]",{'name': 'B. Pantoja'},B. Pantoja,"[{'href': 'http://arxiv.org/abs/2106.10754v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.10754v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'astro-ph.EP', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'astro-ph.EP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'astro-ph.SR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]","32 pages, 22 figures","A&A, A39, 650, 2021,",
http://arxiv.org/abs/2106.10951v1,True,http://arxiv.org/abs/2106.10951v1,2021-06-21T09:46:36Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=21, tm_hour=9, tm_min=46, tm_sec=36, tm_wday=0, tm_yday=172, tm_isdst=0)",2021-06-21T09:46:36Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=21, tm_hour=9, tm_min=46, tm_sec=36, tm_wday=0, tm_yday=172, tm_isdst=0)","Discovering Equations that Govern Experimental Materials Stability under
  Environmental Stress using Scientific Machine Learning","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Discovering Equations that Govern Experimental Materials Stability under\n  Environmental Stress using Scientific Machine Learning'}","While machine learning (ML) in experimental research has demonstrated
impressive predictive capabilities, inductive reasoning and knowledge
extraction remain elusive tasks, in part because of the difficulty extracting
fungible knowledge representations from experimental data. In this manuscript,
we use ML to infer the underlying dynamical differential equation (DE) from
experimental data of degrading organic-inorganic methylammonium lead iodide
(MAPI) perovskite thin films under environmental stressors (elevated
temperature, humidity, and light). We apply a sparse regression algorithm that
automatically identifies the differential equation describing the dynamics from
time-series data. We find that the underlying DE governing MAPI degradation
across a broad temperature range of 35 to 85{\deg}C is described minimally with
three terms (specifically, a second-order polynomial), and not a simple
single-order reaction (i.e. 0th, 1st, or 2nd-order reaction). We demonstrate
how computer-derived results can aid the researcher to develop profound
mechanistic insights. This DE corresponds to the Verhulst logistic function,
which describes reaction kinetics analogous in functional form to autocatalytic
or self-propagating reactions, suggesting future strategies to suppress MAPI
degradation. We examine the robustness of our conclusions to experimental
luck-of-the-draw variance and Gaussian noise using a combination of experiment
and simulation, and describe the experimental limits within which this
methodology can be applied. Our study demonstrates the application of
scientific ML in experimental chemical and materials systems, highlighting the
promise and challenges associated with ML-aided scientific discovery.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'While machine learning (ML) in experimental research has demonstrated\nimpressive predictive capabilities, inductive reasoning and knowledge\nextraction remain elusive tasks, in part because of the difficulty extracting\nfungible knowledge representations from experimental data. In this manuscript,\nwe use ML to infer the underlying dynamical differential equation (DE) from\nexperimental data of degrading organic-inorganic methylammonium lead iodide\n(MAPI) perovskite thin films under environmental stressors (elevated\ntemperature, humidity, and light). We apply a sparse regression algorithm that\nautomatically identifies the differential equation describing the dynamics from\ntime-series data. We find that the underlying DE governing MAPI degradation\nacross a broad temperature range of 35 to 85{\\deg}C is described minimally with\nthree terms (specifically, a second-order polynomial), and not a simple\nsingle-order reaction (i.e. 0th, 1st, or 2nd-order reaction). We demonstrate\nhow computer-derived results can aid the researcher to develop profound\nmechanistic insights. This DE corresponds to the Verhulst logistic function,\nwhich describes reaction kinetics analogous in functional form to autocatalytic\nor self-propagating reactions, suggesting future strategies to suppress MAPI\ndegradation. We examine the robustness of our conclusions to experimental\nluck-of-the-draw variance and Gaussian noise using a combination of experiment\nand simulation, and describe the experimental limits within which this\nmethodology can be applied. Our study demonstrates the application of\nscientific ML in experimental chemical and materials systems, highlighting the\npromise and challenges associated with ML-aided scientific discovery.'}","[{'name': 'Richa Ramesh Naik'}, {'name': 'Armi Tiihonen'}, {'name': 'Janak Thapa'}, {'name': 'Clio Batali'}, {'name': 'Zhe Liu'}, {'name': 'Shijing Sun'}, {'name': 'Tonio Buonassisi'}]",{'name': 'Tonio Buonassisi'},Tonio Buonassisi,"[{'href': 'http://arxiv.org/abs/2106.10951v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.10951v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cond-mat.mtrl-sci', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cond-mat.mtrl-sci', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",,,
http://arxiv.org/abs/2106.10952v1,True,http://arxiv.org/abs/2106.10952v1,2021-06-21T09:48:03Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=21, tm_hour=9, tm_min=48, tm_sec=3, tm_wday=0, tm_yday=172, tm_isdst=0)",2021-06-21T09:48:03Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=21, tm_hour=9, tm_min=48, tm_sec=3, tm_wday=0, tm_yday=172, tm_isdst=0)","Spliced Binned-Pareto Distribution for Robust Modeling of Heavy-tailed
  Time Series","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Spliced Binned-Pareto Distribution for Robust Modeling of Heavy-tailed\n  Time Series'}","This work proposes a novel method to robustly and accurately model time
series with heavy-tailed noise, in non-stationary scenarios. In many practical
application time series have heavy-tailed noise that significantly impacts the
performance of classical forecasting models; in particular, accurately modeling
a distribution over extreme events is crucial to performing accurate time
series anomaly detection. We propose a Spliced Binned-Pareto distribution which
is both robust to extreme observations and allows accurate modeling of the full
distribution. Our method allows the capture of time dependencies in the higher
order moments of the distribution such as the tail heaviness. We compare the
robustness and the accuracy of the tail estimation of our method to other state
of the art methods on Twitter mentions count time series.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'This work proposes a novel method to robustly and accurately model time\nseries with heavy-tailed noise, in non-stationary scenarios. In many practical\napplication time series have heavy-tailed noise that significantly impacts the\nperformance of classical forecasting models; in particular, accurately modeling\na distribution over extreme events is crucial to performing accurate time\nseries anomaly detection. We propose a Spliced Binned-Pareto distribution which\nis both robust to extreme observations and allows accurate modeling of the full\ndistribution. Our method allows the capture of time dependencies in the higher\norder moments of the distribution such as the tail heaviness. We compare the\nrobustness and the accuracy of the tail estimation of our method to other state\nof the art methods on Twitter mentions count time series.'}","[{'name': 'Elena Ehrlich'}, {'name': 'Laurent Callot'}, {'name': 'Fran√ßois-Xavier Aubet'}]",{'name': 'Fran√ßois-Xavier Aubet'},Fran√ßois-Xavier Aubet,"[{'href': 'http://arxiv.org/abs/2106.10952v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.10952v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.CO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]","Accepted at RobustWorkshop@ICLR2021:
  <https://sites.google.com/connect.hku.hk/robustml-2021/accepted-papers/paper-041>",,
http://arxiv.org/abs/2106.11000v1,True,http://arxiv.org/abs/2106.11000v1,2021-06-21T11:40:00Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=21, tm_hour=11, tm_min=40, tm_sec=0, tm_wday=0, tm_yday=172, tm_isdst=0)",2021-06-21T11:40:00Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=21, tm_hour=11, tm_min=40, tm_sec=0, tm_wday=0, tm_yday=172, tm_isdst=0)",A Comparative Study of Online Disinformation and Offline Protests,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'A Comparative Study of Online Disinformation and Offline Protests'}","In early 2021 the United States Capitol in Washington was stormed during a
riot and violent attack. Although the storming was merely an instance in a long
sequence of events, it provided a testimony for many observers who had claimed
that online actions, including the propagation of disinformation, have offline
consequences. Soon after, a number of papers have been published about the
relation between online disinformation and offline violence, among other
related relations. Hitherto, the effects upon political protests have been
unexplored. This paper thus evaluates such effects with a time series
cross-sectional sample of 125 countries in a period between 2000 and 2019. The
results are mixed. Based on Bayesian multi-level regression modeling, (i) there
indeed is an effect between online disinformation and offline protests, but the
effect is partially meditated by political polarization. The results are
clearer in a sample of countries belonging to the European Economic Area. With
this sample, (ii) offline protest counts increase from online disinformation
disseminated by domestic governments, political parties, and politicians as
well as by foreign governments. Furthermore, (iii) Internet shutdowns and
governmental monitoring of social media tend to decrease the counts. With these
results, the paper contributes to the blossoming disinformation research by
modeling the impact of disinformation upon offline phenomenon. The contribution
is important due to the various policy measures planned or already enacted.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'In early 2021 the United States Capitol in Washington was stormed during a\nriot and violent attack. Although the storming was merely an instance in a long\nsequence of events, it provided a testimony for many observers who had claimed\nthat online actions, including the propagation of disinformation, have offline\nconsequences. Soon after, a number of papers have been published about the\nrelation between online disinformation and offline violence, among other\nrelated relations. Hitherto, the effects upon political protests have been\nunexplored. This paper thus evaluates such effects with a time series\ncross-sectional sample of 125 countries in a period between 2000 and 2019. The\nresults are mixed. Based on Bayesian multi-level regression modeling, (i) there\nindeed is an effect between online disinformation and offline protests, but the\neffect is partially meditated by political polarization. The results are\nclearer in a sample of countries belonging to the European Economic Area. With\nthis sample, (ii) offline protest counts increase from online disinformation\ndisseminated by domestic governments, political parties, and politicians as\nwell as by foreign governments. Furthermore, (iii) Internet shutdowns and\ngovernmental monitoring of social media tend to decrease the counts. With these\nresults, the paper contributes to the blossoming disinformation research by\nmodeling the impact of disinformation upon offline phenomenon. The contribution\nis important due to the various policy measures planned or already enacted.'}",[{'name': 'Jukka Ruohonen'}],{'name': 'Jukka Ruohonen'},Jukka Ruohonen,"[{'href': 'http://arxiv.org/abs/2106.11000v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.11000v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",Submitted,,
http://arxiv.org/abs/2106.11028v1,True,http://arxiv.org/abs/2106.11028v1,2021-06-21T12:23:45Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=21, tm_hour=12, tm_min=23, tm_sec=45, tm_wday=0, tm_yday=172, tm_isdst=0)",2021-06-21T12:23:45Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=21, tm_hour=12, tm_min=23, tm_sec=45, tm_wday=0, tm_yday=172, tm_isdst=0)",Neural Controlled Differential Equations for Online Prediction Tasks,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Neural Controlled Differential Equations for Online Prediction Tasks'}","Neural controlled differential equations (Neural CDEs) are a continuous-time
extension of recurrent neural networks (RNNs), achieving state-of-the-art
(SOTA) performance at modelling functions of irregular time series. In order to
interpret discrete data in continuous time, current implementations rely on
non-causal interpolations of the data. This is fine when the whole time series
is observed in advance, but means that Neural CDEs are not suitable for use in
\textit{online prediction tasks}, where predictions need to be made in
real-time: a major use case for recurrent networks. Here, we show how this
limitation may be rectified. First, we identify several theoretical conditions
that interpolation schemes for Neural CDEs should satisfy, such as boundedness
and uniqueness. Second, we use these to motivate the introduction of new
schemes that address these conditions, offering in particular measurability
(for online prediction), and smoothness (for speed). Third, we empirically
benchmark our online Neural CDE model on three continuous monitoring tasks from
the MIMIC-IV medical database: we demonstrate improved performance on all tasks
against ODE benchmarks, and on two of the three tasks against SOTA non-ODE
benchmarks.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Neural controlled differential equations (Neural CDEs) are a continuous-time\nextension of recurrent neural networks (RNNs), achieving state-of-the-art\n(SOTA) performance at modelling functions of irregular time series. In order to\ninterpret discrete data in continuous time, current implementations rely on\nnon-causal interpolations of the data. This is fine when the whole time series\nis observed in advance, but means that Neural CDEs are not suitable for use in\n\\textit{online prediction tasks}, where predictions need to be made in\nreal-time: a major use case for recurrent networks. Here, we show how this\nlimitation may be rectified. First, we identify several theoretical conditions\nthat interpolation schemes for Neural CDEs should satisfy, such as boundedness\nand uniqueness. Second, we use these to motivate the introduction of new\nschemes that address these conditions, offering in particular measurability\n(for online prediction), and smoothness (for speed). Third, we empirically\nbenchmark our online Neural CDE model on three continuous monitoring tasks from\nthe MIMIC-IV medical database: we demonstrate improved performance on all tasks\nagainst ODE benchmarks, and on two of the three tasks against SOTA non-ODE\nbenchmarks.'}","[{'name': 'James Morrill'}, {'name': 'Patrick Kidger'}, {'name': 'Lingyi Yang'}, {'name': 'Terry Lyons'}]",{'name': 'Terry Lyons'},Terry Lyons,"[{'href': 'http://arxiv.org/abs/2106.11028v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.11028v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",,,
http://arxiv.org/abs/2106.11043v1,True,http://arxiv.org/abs/2106.11043v1,2021-06-21T12:29:02Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=21, tm_hour=12, tm_min=29, tm_sec=2, tm_wday=0, tm_yday=172, tm_isdst=0)",2021-06-21T12:29:02Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=21, tm_hour=12, tm_min=29, tm_sec=2, tm_wday=0, tm_yday=172, tm_isdst=0)",Scalable Bayesian inference for time series via divide-and-conquer,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Scalable Bayesian inference for time series via divide-and-conquer'}","Bayesian computational algorithms tend to scale poorly as data size
increases. This had led to the development of divide-and-conquer-based
approaches for scalable inference. These divide the data into subsets, perform
inference for each subset in parallel, and then combine these inferences. While
appealing theoretical properties and practical performance have been
demonstrated for independent observations, scalable inference for dependent
data remains challenging. In this work, we study the problem of Bayesian
inference from very long time series. The literature in this area focuses
mainly on approximate approaches that lack any theoretical guarantees and may
provide arbitrarily poor accuracy in practice. We propose a simple and scalable
divide-and-conquer method, and provide accuracy guarantees. Numerical
simulations and real data applications demonstrate the effectiveness of our
approach.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Bayesian computational algorithms tend to scale poorly as data size\nincreases. This had led to the development of divide-and-conquer-based\napproaches for scalable inference. These divide the data into subsets, perform\ninference for each subset in parallel, and then combine these inferences. While\nappealing theoretical properties and practical performance have been\ndemonstrated for independent observations, scalable inference for dependent\ndata remains challenging. In this work, we study the problem of Bayesian\ninference from very long time series. The literature in this area focuses\nmainly on approximate approaches that lack any theoretical guarantees and may\nprovide arbitrarily poor accuracy in practice. We propose a simple and scalable\ndivide-and-conquer method, and provide accuracy guarantees. Numerical\nsimulations and real data applications demonstrate the effectiveness of our\napproach.'}","[{'name': 'Rihui Ou'}, {'name': 'Deborshee Sen'}, {'name': 'David Dunson'}]",{'name': 'David Dunson'},David Dunson,"[{'href': 'http://arxiv.org/abs/2106.11043v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.11043v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'stat.ME', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'stat.ME', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.CO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",,,
http://arxiv.org/abs/2106.11277v1,True,http://arxiv.org/abs/2106.11277v1,2021-06-21T17:27:11Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=21, tm_hour=17, tm_min=27, tm_sec=11, tm_wday=0, tm_yday=172, tm_isdst=0)",2021-06-21T17:27:11Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=21, tm_hour=17, tm_min=27, tm_sec=11, tm_wday=0, tm_yday=172, tm_isdst=0)","Attention-based Neural Network for Driving Environment Complexity
  Perception","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Attention-based Neural Network for Driving Environment Complexity\n  Perception'}","Environment perception is crucial for autonomous vehicle (AV) safety. Most
existing AV perception algorithms have not studied the surrounding environment
complexity and failed to include the environment complexity parameter. This
paper proposes a novel attention-based neural network model to predict the
complexity level of the surrounding driving environment. The proposed model
takes naturalistic driving videos and corresponding vehicle dynamics parameters
as input. It consists of a Yolo-v3 object detection algorithm, a heat map
generation algorithm, CNN-based feature extractors, and attention-based feature
extractors for both video and time-series vehicle dynamics data inputs to
extract features. The output from the proposed algorithm is a surrounding
environment complexity parameter. The Berkeley DeepDrive dataset (BDD Dataset)
and subjectively labeled surrounding environment complexity levels are used for
model training and validation to evaluate the algorithm. The proposed
attention-based network achieves 91.22% average classification accuracy to
classify the surrounding environment complexity. It proves that the environment
complexity level can be accurately predicted and applied for future AVs'
environment perception studies.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': ""Environment perception is crucial for autonomous vehicle (AV) safety. Most\nexisting AV perception algorithms have not studied the surrounding environment\ncomplexity and failed to include the environment complexity parameter. This\npaper proposes a novel attention-based neural network model to predict the\ncomplexity level of the surrounding driving environment. The proposed model\ntakes naturalistic driving videos and corresponding vehicle dynamics parameters\nas input. It consists of a Yolo-v3 object detection algorithm, a heat map\ngeneration algorithm, CNN-based feature extractors, and attention-based feature\nextractors for both video and time-series vehicle dynamics data inputs to\nextract features. The output from the proposed algorithm is a surrounding\nenvironment complexity parameter. The Berkeley DeepDrive dataset (BDD Dataset)\nand subjectively labeled surrounding environment complexity levels are used for\nmodel training and validation to evaluate the algorithm. The proposed\nattention-based network achieves 91.22% average classification accuracy to\nclassify the surrounding environment complexity. It proves that the environment\ncomplexity level can be accurately predicted and applied for future AVs'\nenvironment perception studies.""}","[{'name': 'Ce Zhang'}, {'name': 'Azim Eskandarian'}, {'name': 'Xuelai Du'}]",{'name': 'Xuelai Du'},Xuelai Du,"[{'href': 'http://arxiv.org/abs/2106.11277v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.11277v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'eess.IV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",Accepted by 2021 IEEE Intelligent Transportation Systems Conference,,
http://arxiv.org/abs/2106.11518v1,True,http://arxiv.org/abs/2106.11518v1,2021-06-22T03:19:14Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=22, tm_hour=3, tm_min=19, tm_sec=14, tm_wday=1, tm_yday=173, tm_isdst=0)",2021-06-22T03:19:14Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=22, tm_hour=3, tm_min=19, tm_sec=14, tm_wday=1, tm_yday=173, tm_isdst=0)",AGB interlopers in YSO catalogues hunted out by NEOWISE,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'AGB interlopers in YSO catalogues hunted out by NEOWISE'}","AGBs and YSOs often share the same domains in IR color-magnitude or
color-color diagrams leading to potential mis-classification. We extracted a
list of AGB interlopers from the published YSO catalogues using the periodogram
analysis on NEOWISE time series data. YSO IR variability is typically
stochastic and linked to episodic mass accretion. Furthermore, most variable
YSOs are at an early evolutionary stage, with significant surrounding envelope
and/or disk material. In contrast, AGBs are often identified by a well defined
sinusoidal variability with periods of a few hundreds days. From our
periodogram analysis of all known low mass YSOs in the Gould Belt, we find 85
AGB candidates, out of which 62 were previously classified as late-stage Class
III YSOs. Most of these new AGB candidates have similar IR colors to O-rich
AGBs. We observed 73 of these AGB candidates in the H2O, CH3OH and SiO maser
lines to further reveal their nature. The SiO maser emission was detected in 10
sources, confirming them as AGBs since low mass YSOs, especially Class III
YSOs, do not show such maser emission. The H2O and CH3OH maser lines were
detected in none of our targets.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'AGBs and YSOs often share the same domains in IR color-magnitude or\ncolor-color diagrams leading to potential mis-classification. We extracted a\nlist of AGB interlopers from the published YSO catalogues using the periodogram\nanalysis on NEOWISE time series data. YSO IR variability is typically\nstochastic and linked to episodic mass accretion. Furthermore, most variable\nYSOs are at an early evolutionary stage, with significant surrounding envelope\nand/or disk material. In contrast, AGBs are often identified by a well defined\nsinusoidal variability with periods of a few hundreds days. From our\nperiodogram analysis of all known low mass YSOs in the Gould Belt, we find 85\nAGB candidates, out of which 62 were previously classified as late-stage Class\nIII YSOs. Most of these new AGB candidates have similar IR colors to O-rich\nAGBs. We observed 73 of these AGB candidates in the H2O, CH3OH and SiO maser\nlines to further reveal their nature. The SiO maser emission was detected in 10\nsources, confirming them as AGBs since low mass YSOs, especially Class III\nYSOs, do not show such maser emission. The H2O and CH3OH maser lines were\ndetected in none of our targets.'}","[{'name': 'Jeong-Eun Lee'}, {'name': 'Sieun Lee'}, {'name': 'Seonjae Lee'}, {'name': 'Kyung-Won Suh'}, {'name': 'Se-Hyung Cho'}, {'name': 'Do-Young Byun'}, {'name': 'Wooseok Park'}, {'name': 'Gregory Herczeg'}, {'name': 'Carlos Contreras Pe√±a'}, {'name': 'Doug Johnstone'}]",{'name': 'Doug Johnstone'},Doug Johnstone,"[{'href': 'http://arxiv.org/abs/2106.11518v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.11518v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'astro-ph.SR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'astro-ph.SR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",Accepted for publication in ApJL,,
http://arxiv.org/abs/2106.11635v1,True,http://arxiv.org/abs/2106.11635v1,2021-06-22T09:42:51Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=22, tm_hour=9, tm_min=42, tm_sec=51, tm_wday=1, tm_yday=173, tm_isdst=0)",2021-06-22T09:42:51Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=22, tm_hour=9, tm_min=42, tm_sec=51, tm_wday=1, tm_yday=173, tm_isdst=0)","A two-stage robust optimization approach for oxygen flexible
  distribution under uncertainty in iron and steel plants","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'A two-stage robust optimization approach for oxygen flexible\n  distribution under uncertainty in iron and steel plants'}","Oxygen optimal distribution is one of the most important energy management
problems in the modern iron and steel industry. Normally, the supply of the
energy generation system is determined by the energy demand of manufacturing
processes. However, the balance between supply and demand fluctuates frequently
due to the uncertainty arising in manufacturing processes. In this paper, we
developed an oxygen optimal distribution model considering uncertain demands
and proposed a two-stage robust optimization (TSRO) with a budget-based
uncertainty set that protects the initial distribution decisions with low
conservatism. The main goal of the TSRO model is to make wait-and-see decisions
maximizing production profits and make here-and-now decisions minimizing
operational stability and surplus/shortage penalty. To represent the
uncertainty set of energy demands, we developed a Gaussian process (GP)-based
time series model to forecast the energy demands of continuous processes and a
capacity-constrained scheduling model to generate multi-scenario energy demands
of discrete processes. We carried out extensive computational studies on TSRO
and its components using well-synthetic instances from historical data. The
results of model validation and analysis are promising and demonstrate our
approach is adapted to solve industrial cases under uncertainty.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Oxygen optimal distribution is one of the most important energy management\nproblems in the modern iron and steel industry. Normally, the supply of the\nenergy generation system is determined by the energy demand of manufacturing\nprocesses. However, the balance between supply and demand fluctuates frequently\ndue to the uncertainty arising in manufacturing processes. In this paper, we\ndeveloped an oxygen optimal distribution model considering uncertain demands\nand proposed a two-stage robust optimization (TSRO) with a budget-based\nuncertainty set that protects the initial distribution decisions with low\nconservatism. The main goal of the TSRO model is to make wait-and-see decisions\nmaximizing production profits and make here-and-now decisions minimizing\noperational stability and surplus/shortage penalty. To represent the\nuncertainty set of energy demands, we developed a Gaussian process (GP)-based\ntime series model to forecast the energy demands of continuous processes and a\ncapacity-constrained scheduling model to generate multi-scenario energy demands\nof discrete processes. We carried out extensive computational studies on TSRO\nand its components using well-synthetic instances from historical data. The\nresults of model validation and analysis are promising and demonstrate our\napproach is adapted to solve industrial cases under uncertainty.'}","[{'name': 'Sheng-Long Jiang'}, {'name': 'Gongzhuang Peng'}, {'name': 'I. David L. Bogle'}]",{'name': 'I. David L. Bogle'},I. David L. Bogle,"[{'href': 'http://arxiv.org/abs/2106.11635v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.11635v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'math.OC', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'math.OC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",,,
http://arxiv.org/abs/2106.11911v1,True,http://arxiv.org/abs/2106.11911v1,2021-06-22T16:38:48Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=22, tm_hour=16, tm_min=38, tm_sec=48, tm_wday=1, tm_yday=173, tm_isdst=0)",2021-06-22T16:38:48Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=22, tm_hour=16, tm_min=38, tm_sec=48, tm_wday=1, tm_yday=173, tm_isdst=0)","Residual Networks as Flows of Velocity Fields for Diffeomorphic Time
  Series Alignment","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Residual Networks as Flows of Velocity Fields for Diffeomorphic Time\n  Series Alignment'}","Non-linear (large) time warping is a challenging source of nuisance in
time-series analysis. In this paper, we propose a novel diffeomorphic temporal
transformer network for both pairwise and joint time-series alignment. Our
ResNet-TW (Deep Residual Network for Time Warping) tackles the alignment
problem by compositing a flow of incremental diffeomorphic mappings. Governed
by the flow equation, our Residual Network (ResNet) builds smooth, fluid and
regular flows of velocity fields and consequently generates smooth and
invertible transformations (i.e. diffeomorphic warping functions). Inspired by
the elegant Large Deformation Diffeomorphic Metric Mapping (LDDMM) framework,
the final transformation is built by the flow of time-dependent vector fields
which are none other than the building blocks of our Residual Network. The
latter is naturally viewed as an Eulerian discretization schema of the flow
equation (an ODE). Once trained, our ResNet-TW aligns unseen data by a single
inexpensive forward pass. As we show in experiments on both univariate (84
datasets from UCR archive) and multivariate time-series (MSR Action-3D,
Florence-3D and MSR Daily Activity), ResNet-TW achieves competitive performance
in joint alignment and classification.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Non-linear (large) time warping is a challenging source of nuisance in\ntime-series analysis. In this paper, we propose a novel diffeomorphic temporal\ntransformer network for both pairwise and joint time-series alignment. Our\nResNet-TW (Deep Residual Network for Time Warping) tackles the alignment\nproblem by compositing a flow of incremental diffeomorphic mappings. Governed\nby the flow equation, our Residual Network (ResNet) builds smooth, fluid and\nregular flows of velocity fields and consequently generates smooth and\ninvertible transformations (i.e. diffeomorphic warping functions). Inspired by\nthe elegant Large Deformation Diffeomorphic Metric Mapping (LDDMM) framework,\nthe final transformation is built by the flow of time-dependent vector fields\nwhich are none other than the building blocks of our Residual Network. The\nlatter is naturally viewed as an Eulerian discretization schema of the flow\nequation (an ODE). Once trained, our ResNet-TW aligns unseen data by a single\ninexpensive forward pass. As we show in experiments on both univariate (84\ndatasets from UCR archive) and multivariate time-series (MSR Action-3D,\nFlorence-3D and MSR Daily Activity), ResNet-TW achieves competitive performance\nin joint alignment and classification.'}","[{'name': 'Hao Huang'}, {'name': 'Boulbaba Ben Amor'}, {'name': 'Xichan Lin'}, {'name': 'Fan Zhu'}, {'name': 'Yi Fang'}]",{'name': 'Yi Fang'},Yi Fang,"[{'href': 'http://arxiv.org/abs/2106.11911v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.11911v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",19 pages,,
http://arxiv.org/abs/2106.12160v1,True,http://arxiv.org/abs/2106.12160v1,2021-06-23T05:00:05Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=23, tm_hour=5, tm_min=0, tm_sec=5, tm_wday=2, tm_yday=174, tm_isdst=0)",2021-06-23T05:00:05Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=23, tm_hour=5, tm_min=0, tm_sec=5, tm_wday=2, tm_yday=174, tm_isdst=0)","COVID-19 Forecasts Using Internet Search Information in the United
  States","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'COVID-19 Forecasts Using Internet Search Information in the United\n  States'}","As the COVID-19 ravaging through the globe, accurate forecasts of the disease
spread is crucial for situational awareness, resource allocation, and public
health decision-making. Alternative to the traditional disease surveillance
data collected by the United States (US) Centers for Disease Control and
Prevention (CDC), big data from Internet such as online search volumes has been
previously shown to contain valuable information for tracking infectious
disease dynamics. In this study, we evaluate the feasibility of using Internet
search volume of relevant queries to track and predict COVID-19 pandemic. We
found strong association between COVID-19 death trend and the search volume of
symptom-related queries such as ""loss of taste"". Then, we further develop an
influenza-tracking model to predict future 2-week COVID-19 deaths on the US
national level, by combining search volume information with COVID-19 time
series information. Encouraged by the 45% error reduction on national level
comparing to the baseline time series model, we additionally build state-level
COVID-19 deaths models, leveraging the cross-state cross-resolution spatial
temporal framework that pools information from search volume and COVID-19
reports across states, regions and the nation. These variants of ARGOX are then
aggregated in a winner-takes-all ensemble fashion to produce the final
state-level 2-week forecasts. Numerical experiments demonstrate that our method
steadily outperforms time series baseline models, and achieves the
state-of-the-art performance among the publicly available benchmark models.
Overall, we show that disease dynamics and relevant public search behaviors
co-evolve during the COVID-19 pandemic, and capturing their dependencies while
leveraging historical cases/deaths as well as spatial-temporal cross-region
information will enable stable and accurate US national and state-level
forecasts.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'As the COVID-19 ravaging through the globe, accurate forecasts of the disease\nspread is crucial for situational awareness, resource allocation, and public\nhealth decision-making. Alternative to the traditional disease surveillance\ndata collected by the United States (US) Centers for Disease Control and\nPrevention (CDC), big data from Internet such as online search volumes has been\npreviously shown to contain valuable information for tracking infectious\ndisease dynamics. In this study, we evaluate the feasibility of using Internet\nsearch volume of relevant queries to track and predict COVID-19 pandemic. We\nfound strong association between COVID-19 death trend and the search volume of\nsymptom-related queries such as ""loss of taste"". Then, we further develop an\ninfluenza-tracking model to predict future 2-week COVID-19 deaths on the US\nnational level, by combining search volume information with COVID-19 time\nseries information. Encouraged by the 45% error reduction on national level\ncomparing to the baseline time series model, we additionally build state-level\nCOVID-19 deaths models, leveraging the cross-state cross-resolution spatial\ntemporal framework that pools information from search volume and COVID-19\nreports across states, regions and the nation. These variants of ARGOX are then\naggregated in a winner-takes-all ensemble fashion to produce the final\nstate-level 2-week forecasts. Numerical experiments demonstrate that our method\nsteadily outperforms time series baseline models, and achieves the\nstate-of-the-art performance among the publicly available benchmark models.\nOverall, we show that disease dynamics and relevant public search behaviors\nco-evolve during the COVID-19 pandemic, and capturing their dependencies while\nleveraging historical cases/deaths as well as spatial-temporal cross-region\ninformation will enable stable and accurate US national and state-level\nforecasts.'}","[{'name': 'Simin Ma'}, {'name': 'Shihao Yang'}]",{'name': 'Shihao Yang'},Shihao Yang,"[{'href': 'http://arxiv.org/abs/2106.12160v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.12160v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'stat.AP', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'stat.AP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]","16 page, 4 figures",,
http://arxiv.org/abs/2106.12226v1,True,http://arxiv.org/abs/2106.12226v1,2021-06-23T08:15:01Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=23, tm_hour=8, tm_min=15, tm_sec=1, tm_wday=2, tm_yday=174, tm_isdst=0)",2021-06-23T08:15:01Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=23, tm_hour=8, tm_min=15, tm_sec=1, tm_wday=2, tm_yday=174, tm_isdst=0)",Sentinel-1 and Sentinel-2 Spatio-Temporal Data Fusion for Clouds Removal,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Sentinel-1 and Sentinel-2 Spatio-Temporal Data Fusion for Clouds Removal'}","The abundance of clouds, located both spatially and temporally, often makes
remote sensing applications with optical images difficult or even impossible.
In this manuscript, a novel method for clouds-corrupted optical image
restoration has been presented and developed, based on a joint data fusion
paradigm, where three deep neural networks have been combined in order to fuse
spatio-temporal features extracted from Sentinel-1 and Sentinel-2 time-series
of data. It is worth highlighting that both the code and the dataset have been
implemented from scratch and made available to interested research for further
analysis and investigation.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'The abundance of clouds, located both spatially and temporally, often makes\nremote sensing applications with optical images difficult or even impossible.\nIn this manuscript, a novel method for clouds-corrupted optical image\nrestoration has been presented and developed, based on a joint data fusion\nparadigm, where three deep neural networks have been combined in order to fuse\nspatio-temporal features extracted from Sentinel-1 and Sentinel-2 time-series\nof data. It is worth highlighting that both the code and the dataset have been\nimplemented from scratch and made available to interested research for further\nanalysis and investigation.'}","[{'name': 'Alessandro Sebastianelli'}, {'name': 'Artur Nowakowski'}, {'name': 'Erika Puglisi'}, {'name': 'Maria Pia Del Rosso'}, {'name': 'Jamila Mifdal'}, {'name': 'Fiora Pirri'}, {'name': 'Pierre Philippe Mathieu'}, {'name': 'Silvia Liberata Ullo'}]",{'name': 'Silvia Liberata Ullo'},Silvia Liberata Ullo,"[{'href': 'http://arxiv.org/abs/2106.12226v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.12226v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'eess.IV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",,,
http://arxiv.org/abs/2106.12271v1,True,http://arxiv.org/abs/2106.12271v1,2021-06-23T09:48:38Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=23, tm_hour=9, tm_min=48, tm_sec=38, tm_wday=2, tm_yday=174, tm_isdst=0)",2021-06-23T09:48:38Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=23, tm_hour=9, tm_min=48, tm_sec=38, tm_wday=2, tm_yday=174, tm_isdst=0)","Unsupervised Speech Enhancement using Dynamical Variational
  Auto-Encoders","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Unsupervised Speech Enhancement using Dynamical Variational\n  Auto-Encoders'}","Dynamical variational auto-encoders (DVAEs) are a class of deep generative
models with latent variables, dedicated to time series data modeling. DVAEs can
be considered as extensions of the variational autoencoder (VAE) that include
the modeling of temporal dependencies between successive observed and/or latent
vectors in data sequences. Previous work has shown the interest of DVAEs and
their better performance over the VAE for speech signals (spectrogram)
modeling. Independently, the VAE has been successfully applied to speech
enhancement in noise, in an unsupervised noise-agnostic set-up that does not
require the use of a parallel dataset of clean and noisy speech samples for
training, but only requires clean speech signals. In this paper, we extend
those works to DVAE-based single-channel unsupervised speech enhancement, hence
exploiting both speech signals unsupervised representation learning and
dynamics modeling. We propose an unsupervised speech enhancement algorithm
based on the most general form of DVAEs, that we then adapt to three specific
DVAE models to illustrate the versatility of the framework. More precisely, we
combine DVAE-based speech priors with a noise model based on nonnegative matrix
factorization, and we derive a variational expectation-maximization (VEM)
algorithm to perform speech enhancement. Experimental results show that the
proposed approach based on DVAEs outperforms its VAE counterpart and a
supervised speech enhancement baseline.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Dynamical variational auto-encoders (DVAEs) are a class of deep generative\nmodels with latent variables, dedicated to time series data modeling. DVAEs can\nbe considered as extensions of the variational autoencoder (VAE) that include\nthe modeling of temporal dependencies between successive observed and/or latent\nvectors in data sequences. Previous work has shown the interest of DVAEs and\ntheir better performance over the VAE for speech signals (spectrogram)\nmodeling. Independently, the VAE has been successfully applied to speech\nenhancement in noise, in an unsupervised noise-agnostic set-up that does not\nrequire the use of a parallel dataset of clean and noisy speech samples for\ntraining, but only requires clean speech signals. In this paper, we extend\nthose works to DVAE-based single-channel unsupervised speech enhancement, hence\nexploiting both speech signals unsupervised representation learning and\ndynamics modeling. We propose an unsupervised speech enhancement algorithm\nbased on the most general form of DVAEs, that we then adapt to three specific\nDVAE models to illustrate the versatility of the framework. More precisely, we\ncombine DVAE-based speech priors with a noise model based on nonnegative matrix\nfactorization, and we derive a variational expectation-maximization (VEM)\nalgorithm to perform speech enhancement. Experimental results show that the\nproposed approach based on DVAEs outperforms its VAE counterpart and a\nsupervised speech enhancement baseline.'}","[{'name': 'Xiaoyu Bie'}, {'name': 'Simon Leglaive'}, {'name': 'Xavier Alameda-Pineda'}, {'name': 'Laurent Girin'}]",{'name': 'Laurent Girin'},Laurent Girin,"[{'href': 'http://arxiv.org/abs/2106.12271v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.12271v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.SD', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.SD', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'eess.AS', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",,,
http://arxiv.org/abs/2106.12382v1,True,http://arxiv.org/abs/2106.12382v1,2021-06-23T13:24:17Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=23, tm_hour=13, tm_min=24, tm_sec=17, tm_wday=2, tm_yday=174, tm_isdst=0)",2021-06-23T13:24:17Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=23, tm_hour=13, tm_min=24, tm_sec=17, tm_wday=2, tm_yday=174, tm_isdst=0)","Innovations Autoencoder and its Application in Real-Time Anomaly
  Detection","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Innovations Autoencoder and its Application in Real-Time Anomaly\n  Detection'}","An innovations sequence of a time series is a sequence of independent and
identically distributed random variables with which the original time series
has a causal representation. The innovation at a time is statistically
independent of the prior history of the time series. As such, it represents the
new information contained at present but not in the past. Because of its simple
probability structure, an innovations sequence is the most efficient signature
of the original. Unlike the principle or independent analysis (PCA/ICA)
representations, an innovations sequence preserves not only the complete
statistical properties but also the temporal order of the original time series.
An long-standing open problem is to find a computationally tractable way to
extract an innovations sequence of non-Gaussian processes. This paper presents
a deep learning approach, referred to as Innovations Autoencoder (IAE), that
extracts innovations sequences using a causal convolutional neural network. An
application of IAE to nonparametric anomaly detection with unknown anomaly and
anomaly-free models is also presented.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'An innovations sequence of a time series is a sequence of independent and\nidentically distributed random variables with which the original time series\nhas a causal representation. The innovation at a time is statistically\nindependent of the prior history of the time series. As such, it represents the\nnew information contained at present but not in the past. Because of its simple\nprobability structure, an innovations sequence is the most efficient signature\nof the original. Unlike the principle or independent analysis (PCA/ICA)\nrepresentations, an innovations sequence preserves not only the complete\nstatistical properties but also the temporal order of the original time series.\nAn long-standing open problem is to find a computationally tractable way to\nextract an innovations sequence of non-Gaussian processes. This paper presents\na deep learning approach, referred to as Innovations Autoencoder (IAE), that\nextracts innovations sequences using a causal convolutional neural network. An\napplication of IAE to nonparametric anomaly detection with unknown anomaly and\nanomaly-free models is also presented.'}","[{'name': 'Xinyi Wang'}, {'name': 'Lang Tong'}]",{'name': 'Lang Tong'},Lang Tong,"[{'href': 'http://arxiv.org/abs/2106.12382v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.12382v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",,,
http://arxiv.org/abs/2106.12407v1,True,http://arxiv.org/abs/2106.12407v1,2021-06-23T13:52:11Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=23, tm_hour=13, tm_min=52, tm_sec=11, tm_wday=2, tm_yday=174, tm_isdst=0)",2021-06-23T13:52:11Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=23, tm_hour=13, tm_min=52, tm_sec=11, tm_wday=2, tm_yday=174, tm_isdst=0)","STRESS: Super-Resolution for Dynamic Fetal MRI using Self-Supervised
  Learning","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'STRESS: Super-Resolution for Dynamic Fetal MRI using Self-Supervised\n  Learning'}","Fetal motion is unpredictable and rapid on the scale of conventional MR scan
times. Therefore, dynamic fetal MRI, which aims at capturing fetal motion and
dynamics of fetal function, is limited to fast imaging techniques with
compromises in image quality and resolution. Super-resolution for dynamic fetal
MRI is still a challenge, especially when multi-oriented stacks of image slices
for oversampling are not available and high temporal resolution for recording
the dynamics of the fetus or placenta is desired. Further, fetal motion makes
it difficult to acquire high-resolution images for supervised learning methods.
To address this problem, in this work, we propose STRESS (Spatio-Temporal
Resolution Enhancement with Simulated Scans), a self-supervised
super-resolution framework for dynamic fetal MRI with interleaved slice
acquisitions. Our proposed method simulates an interleaved slice acquisition
along the high-resolution axis on the originally acquired data to generate
pairs of low- and high-resolution images. Then, it trains a super-resolution
network by exploiting both spatial and temporal correlations in the MR time
series, which is used to enhance the resolution of the original data.
Evaluations on both simulated and in utero data show that our proposed method
outperforms other self-supervised super-resolution methods and improves image
quality, which is beneficial to other downstream tasks and evaluations.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Fetal motion is unpredictable and rapid on the scale of conventional MR scan\ntimes. Therefore, dynamic fetal MRI, which aims at capturing fetal motion and\ndynamics of fetal function, is limited to fast imaging techniques with\ncompromises in image quality and resolution. Super-resolution for dynamic fetal\nMRI is still a challenge, especially when multi-oriented stacks of image slices\nfor oversampling are not available and high temporal resolution for recording\nthe dynamics of the fetus or placenta is desired. Further, fetal motion makes\nit difficult to acquire high-resolution images for supervised learning methods.\nTo address this problem, in this work, we propose STRESS (Spatio-Temporal\nResolution Enhancement with Simulated Scans), a self-supervised\nsuper-resolution framework for dynamic fetal MRI with interleaved slice\nacquisitions. Our proposed method simulates an interleaved slice acquisition\nalong the high-resolution axis on the originally acquired data to generate\npairs of low- and high-resolution images. Then, it trains a super-resolution\nnetwork by exploiting both spatial and temporal correlations in the MR time\nseries, which is used to enhance the resolution of the original data.\nEvaluations on both simulated and in utero data show that our proposed method\noutperforms other self-supervised super-resolution methods and improves image\nquality, which is beneficial to other downstream tasks and evaluations.'}","[{'name': 'Junshen Xu'}, {'name': 'Esra Abaci Turk'}, {'name': 'P. Ellen Grant'}, {'name': 'Polina Golland'}, {'name': 'Elfar Adalsteinsson'}]",{'name': 'Elfar Adalsteinsson'},Elfar Adalsteinsson,"[{'href': 'http://arxiv.org/abs/2106.12407v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.12407v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'eess.IV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'eess.IV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",,,
http://arxiv.org/abs/2106.12430v1,True,http://arxiv.org/abs/2106.12430v1,2021-06-23T14:35:38Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=23, tm_hour=14, tm_min=35, tm_sec=38, tm_wday=2, tm_yday=174, tm_isdst=0)",2021-06-23T14:35:38Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=23, tm_hour=14, tm_min=35, tm_sec=38, tm_wday=2, tm_yday=174, tm_isdst=0)",Beyond Predictions in Neural ODEs: Identification and Interventions,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Beyond Predictions in Neural ODEs: Identification and Interventions'}","Spurred by tremendous success in pattern matching and prediction tasks,
researchers increasingly resort to machine learning to aid original scientific
discovery. Given large amounts of observational data about a system, can we
uncover the rules that govern its evolution? Solving this task holds the great
promise of fully understanding the causal interactions and being able to make
reliable predictions about the system's behavior under interventions. We take a
step towards answering this question for time-series data generated from
systems of ordinary differential equations (ODEs). While the governing ODEs
might not be identifiable from data alone, we show that combining simple
regularization schemes with flexible neural ODEs can robustly recover the
dynamics and causal structures from time-series data. Our results on a variety
of (non)-linear first and second order systems as well as real data validate
our method. We conclude by showing that we can also make accurate predictions
under interventions on variables or the system itself.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': ""Spurred by tremendous success in pattern matching and prediction tasks,\nresearchers increasingly resort to machine learning to aid original scientific\ndiscovery. Given large amounts of observational data about a system, can we\nuncover the rules that govern its evolution? Solving this task holds the great\npromise of fully understanding the causal interactions and being able to make\nreliable predictions about the system's behavior under interventions. We take a\nstep towards answering this question for time-series data generated from\nsystems of ordinary differential equations (ODEs). While the governing ODEs\nmight not be identifiable from data alone, we show that combining simple\nregularization schemes with flexible neural ODEs can robustly recover the\ndynamics and causal structures from time-series data. Our results on a variety\nof (non)-linear first and second order systems as well as real data validate\nour method. We conclude by showing that we can also make accurate predictions\nunder interventions on variables or the system itself.""}","[{'name': 'Hananeh Aliee'}, {'name': 'Fabian J. Theis'}, {'name': 'Niki Kilbertus'}]",{'name': 'Niki Kilbertus'},Niki Kilbertus,"[{'href': 'http://arxiv.org/abs/2106.12430v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.12430v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",,,
http://arxiv.org/abs/2106.12917v1,True,http://arxiv.org/abs/2106.12917v1,2021-06-23T14:40:44Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=23, tm_hour=14, tm_min=40, tm_sec=44, tm_wday=2, tm_yday=174, tm_isdst=0)",2021-06-23T14:40:44Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=23, tm_hour=14, tm_min=40, tm_sec=44, tm_wday=2, tm_yday=174, tm_isdst=0)",Continuous-Time Deep Glioma Growth Models,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Continuous-Time Deep Glioma Growth Models'}","The ability to estimate how a tumor might evolve in the future could have
tremendous clinical benefits, from improved treatment decisions to better dose
distribution in radiation therapy. Recent work has approached the glioma growth
modeling problem via deep learning and variational inference, thus learning
growth dynamics entirely from a real patient data distribution. So far, this
approach was constrained to predefined image acquisition intervals and
sequences of fixed length, which limits its applicability in more realistic
scenarios. We overcome these limitations by extending Neural Processes, a class
of conditional generative models for stochastic time series, with a
hierarchical multi-scale representation encoding including a spatio-temporal
attention mechanism. The result is a learned growth model that can be
conditioned on an arbitrary number of observations, and that can produce a
distribution of temporally consistent growth trajectories on a continuous time
axis. On a dataset of 379 patients, the approach successfully captures both
global and finer-grained variations in the images, exhibiting superior
performance compared to other learned growth models.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'The ability to estimate how a tumor might evolve in the future could have\ntremendous clinical benefits, from improved treatment decisions to better dose\ndistribution in radiation therapy. Recent work has approached the glioma growth\nmodeling problem via deep learning and variational inference, thus learning\ngrowth dynamics entirely from a real patient data distribution. So far, this\napproach was constrained to predefined image acquisition intervals and\nsequences of fixed length, which limits its applicability in more realistic\nscenarios. We overcome these limitations by extending Neural Processes, a class\nof conditional generative models for stochastic time series, with a\nhierarchical multi-scale representation encoding including a spatio-temporal\nattention mechanism. The result is a learned growth model that can be\nconditioned on an arbitrary number of observations, and that can produce a\ndistribution of temporally consistent growth trajectories on a continuous time\naxis. On a dataset of 379 patients, the approach successfully captures both\nglobal and finer-grained variations in the images, exhibiting superior\nperformance compared to other learned growth models.'}","[{'name': 'Jens Petersen'}, {'name': 'Fabian Isensee'}, {'name': 'Gregor K√∂hler'}, {'name': 'Paul F. J√§ger'}, {'name': 'David Zimmerer'}, {'name': 'Ulf Neuberger'}, {'name': 'Wolfgang Wick'}, {'name': 'J√ºrgen Debus'}, {'name': 'Sabine Heiland'}, {'name': 'Martin Bendszus'}, {'name': 'Philipp Vollmuth'}, {'name': 'Klaus H. Maier-Hein'}]",{'name': 'Klaus H. Maier-Hein'},Klaus H. Maier-Hein,"[{'href': 'http://arxiv.org/abs/2106.12917v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.12917v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'eess.IV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'eess.IV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",MICCAI 2021,,
http://arxiv.org/abs/2106.12555v1,True,http://arxiv.org/abs/2106.12555v1,2021-06-23T17:25:43Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=23, tm_hour=17, tm_min=25, tm_sec=43, tm_wday=2, tm_yday=174, tm_isdst=0)",2021-06-23T17:25:43Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=23, tm_hour=17, tm_min=25, tm_sec=43, tm_wday=2, tm_yday=174, tm_isdst=0)",Approximate Bayesian Computation with Path Signatures,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Approximate Bayesian Computation with Path Signatures'}","Simulation models of scientific interest often lack a tractable likelihood
function, precluding standard likelihood-based statistical inference. A popular
likelihood-free method for inferring simulator parameters is approximate
Bayesian computation, where an approximate posterior is sampled by comparing
simulator output and observed data. However, effective measures of closeness
between simulated and observed data are generally difficult to construct,
particularly for time series data which are often high-dimensional and
structurally complex. Existing approaches typically involve manually
constructing summary statistics, requiring substantial domain expertise and
experimentation, or rely on unrealistic assumptions such as iid data. Others
are inappropriate in more complex settings like multivariate or irregularly
sampled time series data. In this paper, we introduce the use of path
signatures as a natural candidate feature set for constructing distances
between time series data for use in approximate Bayesian computation
algorithms. Our experiments show that such an approach can generate more
accurate approximate Bayesian posteriors than existing techniques for time
series models.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Simulation models of scientific interest often lack a tractable likelihood\nfunction, precluding standard likelihood-based statistical inference. A popular\nlikelihood-free method for inferring simulator parameters is approximate\nBayesian computation, where an approximate posterior is sampled by comparing\nsimulator output and observed data. However, effective measures of closeness\nbetween simulated and observed data are generally difficult to construct,\nparticularly for time series data which are often high-dimensional and\nstructurally complex. Existing approaches typically involve manually\nconstructing summary statistics, requiring substantial domain expertise and\nexperimentation, or rely on unrealistic assumptions such as iid data. Others\nare inappropriate in more complex settings like multivariate or irregularly\nsampled time series data. In this paper, we introduce the use of path\nsignatures as a natural candidate feature set for constructing distances\nbetween time series data for use in approximate Bayesian computation\nalgorithms. Our experiments show that such an approach can generate more\naccurate approximate Bayesian posteriors than existing techniques for time\nseries models.'}","[{'name': 'Joel Dyer'}, {'name': 'Patrick Cannon'}, {'name': 'Sebastian M Schmon'}]",{'name': 'Sebastian M Schmon'},Sebastian M Schmon,"[{'href': 'http://arxiv.org/abs/2106.12555v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.12555v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'stat.ME', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'stat.ME', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.CO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]","27 pages, 11 figures",,
http://arxiv.org/abs/2106.12619v1,True,http://arxiv.org/abs/2106.12619v1,2021-06-23T18:27:59Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=23, tm_hour=18, tm_min=27, tm_sec=59, tm_wday=2, tm_yday=174, tm_isdst=0)",2021-06-23T18:27:59Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=23, tm_hour=18, tm_min=27, tm_sec=59, tm_wday=2, tm_yday=174, tm_isdst=0)","Machine learning structure preserving brackets for forecasting
  irreversible processes","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Machine learning structure preserving brackets for forecasting\n  irreversible processes'}","Forecasting of time-series data requires imposition of inductive biases to
obtain predictive extrapolation, and recent works have imposed
Hamiltonian/Lagrangian form to preserve structure for systems with reversible
dynamics. In this work we present a novel parameterization of dissipative
brackets from metriplectic dynamical systems appropriate for learning
irreversible dynamics with unknown a priori model form. The process learns
generalized Casimirs for energy and entropy guaranteed to be conserved and
nondecreasing, respectively. Furthermore, for the case of added thermal noise,
we guarantee exact preservation of a fluctuation-dissipation theorem, ensuring
thermodynamic consistency. We provide benchmarks for dissipative systems
demonstrating learned dynamics are more robust and generalize better than
either ""black-box"" or penalty-based approaches.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Forecasting of time-series data requires imposition of inductive biases to\nobtain predictive extrapolation, and recent works have imposed\nHamiltonian/Lagrangian form to preserve structure for systems with reversible\ndynamics. In this work we present a novel parameterization of dissipative\nbrackets from metriplectic dynamical systems appropriate for learning\nirreversible dynamics with unknown a priori model form. The process learns\ngeneralized Casimirs for energy and entropy guaranteed to be conserved and\nnondecreasing, respectively. Furthermore, for the case of added thermal noise,\nwe guarantee exact preservation of a fluctuation-dissipation theorem, ensuring\nthermodynamic consistency. We provide benchmarks for dissipative systems\ndemonstrating learned dynamics are more robust and generalize better than\neither ""black-box"" or penalty-based approaches.'}","[{'name': 'Kookjin Lee'}, {'name': 'Nathaniel A. Trask'}, {'name': 'Panos Stinis'}]",{'name': 'Panos Stinis'},Panos Stinis,"[{'href': 'http://arxiv.org/abs/2106.12619v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.12619v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'physics.comp-ph', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'physics.comp-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",,,
http://arxiv.org/abs/2106.12758v1,True,http://arxiv.org/abs/2106.12758v1,2021-06-24T03:55:50Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=24, tm_hour=3, tm_min=55, tm_sec=50, tm_wday=3, tm_yday=175, tm_isdst=0)",2021-06-24T03:55:50Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=24, tm_hour=3, tm_min=55, tm_sec=50, tm_wday=3, tm_yday=175, tm_isdst=0)",Neural ODE to model and prognose thermoacoustic instability,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Neural ODE to model and prognose thermoacoustic instability'}","In reacting flow systems, thermoacoustic instability characterized by high
amplitude pressure fluctuations, is driven by a positive coupling between the
unsteady heat release rate and the acoustic field of the combustor. When the
underlying flow is turbulent, as a control parameter of the system is varied
and the system approach thermoacoustic instability, the acoustic pressure
oscillations synchronize with heat release rate oscillations. Consequently,
during the onset of thermoacoustic instability in turbulent combustors, the
system dynamics transition from chaotic oscillations to periodic oscillations
via a state of intermittency. Thermoacoustic systems are traditionally modeled
by coupling the model for the unsteady heat source and the acoustic subsystem,
each estimated independently. The response of the unsteady heat source, the
flame, to acoustic fluctuations are characterized by introducing external
unsteady forcing. This necessitates a powerful excitation module to obtain the
nonlinear response of the flame to acoustic perturbations. Instead of
characterizing individual subsystems, we introduce a neural ordinary
differential equation (neural ODE) framework to model the thermoacoustic system
as a whole. The neural ODE model for the thermoacoustic system uses time series
of the heat release rate and the pressure fluctuations, measured simultaneously
without introducing any external perturbations, to model their coupled
interaction. Further, we use the parameters of neural ODE to define an anomaly
measure that represents the proximity of system dynamics to limit cycle
oscillations and thus provide an early warning signal for the onset of
thermoacoustic instability.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'In reacting flow systems, thermoacoustic instability characterized by high\namplitude pressure fluctuations, is driven by a positive coupling between the\nunsteady heat release rate and the acoustic field of the combustor. When the\nunderlying flow is turbulent, as a control parameter of the system is varied\nand the system approach thermoacoustic instability, the acoustic pressure\noscillations synchronize with heat release rate oscillations. Consequently,\nduring the onset of thermoacoustic instability in turbulent combustors, the\nsystem dynamics transition from chaotic oscillations to periodic oscillations\nvia a state of intermittency. Thermoacoustic systems are traditionally modeled\nby coupling the model for the unsteady heat source and the acoustic subsystem,\neach estimated independently. The response of the unsteady heat source, the\nflame, to acoustic fluctuations are characterized by introducing external\nunsteady forcing. This necessitates a powerful excitation module to obtain the\nnonlinear response of the flame to acoustic perturbations. Instead of\ncharacterizing individual subsystems, we introduce a neural ordinary\ndifferential equation (neural ODE) framework to model the thermoacoustic system\nas a whole. The neural ODE model for the thermoacoustic system uses time series\nof the heat release rate and the pressure fluctuations, measured simultaneously\nwithout introducing any external perturbations, to model their coupled\ninteraction. Further, we use the parameters of neural ODE to define an anomaly\nmeasure that represents the proximity of system dynamics to limit cycle\noscillations and thus provide an early warning signal for the onset of\nthermoacoustic instability.'}","[{'name': 'Jayesh Dhadphale'}, {'name': 'Vishnu R. Unni'}, {'name': 'Abhishek Saha'}, {'name': 'R. I. Sujith'}]",{'name': 'R. I. Sujith'},R. I. Sujith,"[{'href': 'http://arxiv.org/abs/2106.12758v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.12758v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'physics.flu-dyn', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'physics.flu-dyn', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'nlin.CD', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]","31 pages, 12 figures",,
http://arxiv.org/abs/2106.12822v1,True,http://arxiv.org/abs/2106.12822v1,2021-06-24T08:21:38Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=24, tm_hour=8, tm_min=21, tm_sec=38, tm_wday=3, tm_yday=175, tm_isdst=0)",2021-06-24T08:21:38Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=24, tm_hour=8, tm_min=21, tm_sec=38, tm_wday=3, tm_yday=175, tm_isdst=0)","Threshold selection for cluster inference based on large deviation
  principles","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Threshold selection for cluster inference based on large deviation\n  principles'}","In the setting of regularly varying time series, a cluster of exceedances is
a short period for which the supremum norm exceeds a high threshold. We propose
to study a generalization of this notion considering short periods, or blocks,
with p--norm above a high threshold. We derive large deviation principles of
blocks and apply these results to improve cluster inference. We focus on blocks
estimators and show they are consistent when we use large empirical quantiles
from the p --norm of blocks as threshold levels. We derive an adaptive
threshold selection method for cluster inference in p. Our approach focuses on
the case p < $\infty$ rather than the classical one for p = $\infty$ where the
bias is more difficult to control.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'In the setting of regularly varying time series, a cluster of exceedances is\na short period for which the supremum norm exceeds a high threshold. We propose\nto study a generalization of this notion considering short periods, or blocks,\nwith p--norm above a high threshold. We derive large deviation principles of\nblocks and apply these results to improve cluster inference. We focus on blocks\nestimators and show they are consistent when we use large empirical quantiles\nfrom the p --norm of blocks as threshold levels. We derive an adaptive\nthreshold selection method for cluster inference in p. Our approach focuses on\nthe case p < $\\infty$ rather than the classical one for p = $\\infty$ where the\nbias is more difficult to control.'}","[{'name': 'Gloria Buritic√°'}, {'name': 'Thomas Mikosch'}, {'name': 'Olivier Wintenberger'}]",{'name': 'Olivier Wintenberger'},Olivier Wintenberger,"[{'href': 'http://arxiv.org/abs/2106.12822v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.12822v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'math.PR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'math.PR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",,,LPSM
http://arxiv.org/abs/2106.13008v1,True,http://arxiv.org/abs/2106.13008v1,2021-06-24T13:43:43Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=24, tm_hour=13, tm_min=43, tm_sec=43, tm_wday=3, tm_yday=175, tm_isdst=0)",2021-06-24T13:43:43Z,"time.struct_time(tm_year=2021, tm_mon=6, tm_mday=24, tm_hour=13, tm_min=43, tm_sec=43, tm_wday=3, tm_yday=175, tm_isdst=0)","Autoformer: Decomposition Transformers with Auto-Correlation for
  Long-Term Series Forecasting","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Autoformer: Decomposition Transformers with Auto-Correlation for\n  Long-Term Series Forecasting'}","Extending the forecasting time is a critical demand for real applications,
such as extreme weather early warning and long-term energy consumption
planning. This paper studies the \textit{long-term forecasting} problem of time
series. Prior Transformer-based models adopt various self-attention mechanisms
to discover the long-range dependencies. However, intricate temporal patterns
of the long-term future prohibit the model from finding reliable dependencies.
Also, Transformers have to adopt the sparse versions of point-wise
self-attentions for long series efficiency, resulting in the information
utilization bottleneck. Towards these challenges, we propose Autoformer as a
novel decomposition architecture with an Auto-Correlation mechanism. We go
beyond the pre-processing convention of series decomposition and renovate it as
a basic inner block of deep models. This design empowers Autoformer with
progressive decomposition capacities for complex time series. Further, inspired
by the stochastic process theory, we design the Auto-Correlation mechanism
based on the series periodicity, which conducts the dependencies discovery and
representation aggregation at the sub-series level. Auto-Correlation
outperforms self-attention in both efficiency and accuracy. In long-term
forecasting, Autoformer yields state-of-the-art accuracy, with a 38% relative
improvement on six benchmarks, covering five practical applications: energy,
traffic, economics, weather and disease.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=%22time+series%22&start=12000&max_results=1000&sortBy=submittedDate&sortOrder=ascending', 'value': 'Extending the forecasting time is a critical demand for real applications,\nsuch as extreme weather early warning and long-term energy consumption\nplanning. This paper studies the \\textit{long-term forecasting} problem of time\nseries. Prior Transformer-based models adopt various self-attention mechanisms\nto discover the long-range dependencies. However, intricate temporal patterns\nof the long-term future prohibit the model from finding reliable dependencies.\nAlso, Transformers have to adopt the sparse versions of point-wise\nself-attentions for long series efficiency, resulting in the information\nutilization bottleneck. Towards these challenges, we propose Autoformer as a\nnovel decomposition architecture with an Auto-Correlation mechanism. We go\nbeyond the pre-processing convention of series decomposition and renovate it as\na basic inner block of deep models. This design empowers Autoformer with\nprogressive decomposition capacities for complex time series. Further, inspired\nby the stochastic process theory, we design the Auto-Correlation mechanism\nbased on the series periodicity, which conducts the dependencies discovery and\nrepresentation aggregation at the sub-series level. Auto-Correlation\noutperforms self-attention in both efficiency and accuracy. In long-term\nforecasting, Autoformer yields state-of-the-art accuracy, with a 38% relative\nimprovement on six benchmarks, covering five practical applications: energy,\ntraffic, economics, weather and disease.'}","[{'name': 'Haixu Wu'}, {'name': 'Jiehui Xu'}, {'name': 'Jianmin Wang'}, {'name': 'Mingsheng Long'}]",{'name': 'Mingsheng Long'},Mingsheng Long,"[{'href': 'http://arxiv.org/abs/2106.13008v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2106.13008v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",,,
